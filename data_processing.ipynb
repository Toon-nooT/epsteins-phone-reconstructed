{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Epstein Estate Documents - Email Processing\n",
    "\n",
    "This notebook is a data-science pipeline processing <strong>23,124 images</strong> and thousands of OCR text files released by the <strong>U.S. House Committee on Oversight and Government Reform</strong> in 2025. Using a combination of OCR cleanup, vision-LLM extraction, name normalization, timestamp reconstruction, and thread mapping, these public images were transformed into a clean, coherent <strong>SQLite message database</strong>. The resulting db file can be used in the GUI phone-like viewer. It supposes you download the source files:\n",
    "[U.S. House Oversight Committee - November 12, 2025](https://oversight.house.gov/release/oversight-committee-releases-additional-epstein-estate-documents/) and set up the .env file (example is provided). The file 'emails_list.csv' is also taken from these source files.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: C:\\Projects\\datasets\\Epstein Estate Documents - Seventh Production\n",
      "Model: Qwen/Qwen2.5-VL-72B-Instruct\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import sqlite3\n",
    "import json\n",
    "import base64\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import re\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from threading import Lock\n",
    "from tqdm import tqdm\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "OPENAI_API_URL = os.getenv('OPENAI_API_URL')\n",
    "OPENAI_API_MODEL = os.getenv('OPENAI_API_MODEL')\n",
    "DATASET_ROOT = Path(os.getenv('DATASET_ROOT_PATH'))\n",
    "\n",
    "print(f\"Dataset: {DATASET_ROOT}\")\n",
    "print(f\"Model: {OPENAI_API_MODEL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client initialized\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI(api_key=OPENAI_API_KEY, base_url=OPENAI_API_URL)\n",
    "DB_PATH = 'emails.db'\n",
    "db_lock = Lock()  # Thread-safe database access\n",
    "print(\"Client initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete database if it still exists from a previous run\n",
    "import os\n",
    "if os.path.exists(DB_PATH):\n",
    "    os.remove(DB_PATH)\n",
    "    print(\"Database deleted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database initialized: emails.db\n"
     ]
    }
   ],
   "source": [
    "def init_database():\n",
    "    conn = sqlite3.connect(DB_PATH)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS email_documents (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        filename TEXT NOT NULL UNIQUE,\n",
    "        subject TEXT,\n",
    "        num_pages INTEGER,\n",
    "        file_size_kb REAL,\n",
    "        processed_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "        processing_status TEXT DEFAULT 'pending',\n",
    "        error_message TEXT\n",
    "    )\n",
    "    ''')\n",
    "    cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS messages (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        email_document_id INTEGER NOT NULL,\n",
    "        source_filename TEXT,\n",
    "        subject TEXT,\n",
    "        message_order INTEGER NOT NULL,\n",
    "        from_address TEXT,\n",
    "        to_address TEXT,\n",
    "        other_recipients TEXT,\n",
    "        timestamp_raw TEXT,\n",
    "        timestamp_iso TEXT,\n",
    "        message_html TEXT,\n",
    "        document_id TEXT,\n",
    "        FOREIGN KEY (email_document_id) REFERENCES email_documents(id)\n",
    "    )\n",
    "    ''')\n",
    "    cursor.execute('CREATE INDEX IF NOT EXISTS idx_messages_timestamp ON messages(timestamp_iso)')\n",
    "    cursor.execute('CREATE INDEX IF NOT EXISTS idx_messages_filename ON messages(source_filename)')\n",
    "    cursor.execute('CREATE INDEX IF NOT EXISTS idx_messages_subject ON messages(subject)')\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    print(f\"Database initialized: {DB_PATH}\")\n",
    "\n",
    "init_database()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper functions defined\n"
     ]
    }
   ],
   "source": [
    "def get_text_file_path(filename):\n",
    "    \"\"\"Find TEXT file in subdirectories\"\"\"\n",
    "    text_dir = DATASET_ROOT / 'TEXT'\n",
    "    pattern = f\"**/{filename}\"\n",
    "    matching_files = list(text_dir.glob(pattern))\n",
    "    if matching_files:\n",
    "        return matching_files[0]\n",
    "    return None\n",
    "\n",
    "def get_image_paths(page_number, num_pages):\n",
    "    images_dir = DATASET_ROOT / 'IMAGES'\n",
    "    image_paths = []\n",
    "    for i in range(num_pages):\n",
    "        page_num = page_number + i\n",
    "        pattern = f\"**/HOUSE_OVERSIGHT_{page_num:06d}.jpg\"\n",
    "        matching_files = list(images_dir.glob(pattern))\n",
    "        if matching_files:\n",
    "            image_paths.append(matching_files[0])\n",
    "    return image_paths\n",
    "\n",
    "def resize_and_encode_image(image_path, target_height=800):\n",
    "    try:\n",
    "        img = Image.open(image_path)\n",
    "        aspect_ratio = img.width / img.height\n",
    "        new_width = int(aspect_ratio * target_height)\n",
    "        img_resized = img.resize((new_width, target_height), Image.Resampling.LANCZOS)\n",
    "        buffer = BytesIO()\n",
    "        img_resized.save(buffer, format='JPEG', quality=85)\n",
    "        return base64.b64encode(buffer.getvalue()).decode('utf-8')\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "\n",
    "print(\"Helper functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON cleaning functions defined\n"
     ]
    }
   ],
   "source": [
    "def clean_and_extract_json(response_text):\n",
    "    \"\"\"Robustly extract and clean JSON from LLM response\"\"\"\n",
    "    try:\n",
    "        # Remove code block markers if present\n",
    "        if response_text.startswith('```'):\n",
    "            lines = response_text.split('\\n')\n",
    "            # Find the start and end of the JSON block\n",
    "            start_idx = 1 if lines[0].strip() == '```' else 0\n",
    "            if lines[start_idx].strip().lower() == 'json':\n",
    "                start_idx += 1\n",
    "            end_idx = len(lines) - 1\n",
    "            if lines[end_idx].strip() == '```':\n",
    "                end_idx -= 1\n",
    "            response_text = '\\n'.join(lines[start_idx:end_idx+1])\n",
    "        \n",
    "        # Remove leading \"json\" if present\n",
    "        response_text = response_text.strip()\n",
    "        if response_text.lower().startswith('json'):\n",
    "            response_text = response_text[4:].strip()\n",
    "        \n",
    "        # Try parsing as-is first\n",
    "        try:\n",
    "            return json.loads(response_text)\n",
    "        except json.JSONDecodeError:\n",
    "            pass\n",
    "        \n",
    "        # Find the main JSON object using regex\n",
    "        import re\n",
    "        json_match = re.search(r'\\{.*\\}', response_text, re.DOTALL)\n",
    "        if not json_match:\n",
    "            raise ValueError(\"No JSON object found in response\")\n",
    "        \n",
    "        json_str = json_match.group()\n",
    "        \n",
    "        # Try parsing the extracted JSON\n",
    "        try:\n",
    "            return json.loads(json_str)\n",
    "        except json.JSONDecodeError as e:\n",
    "            # If it still fails, try to fix common issues\n",
    "            # Fix unescaped quotes in string values\n",
    "            fixed_json = re.sub(r'(?<!\\\\)\"(?=[^,}\\]:]*[^\"\\\\]\")', r'\\\\\"', json_str)\n",
    "            \n",
    "            # Try one more time\n",
    "            try:\n",
    "                return json.loads(fixed_json)\n",
    "            except json.JSONDecodeError:\n",
    "                # Last resort: try to extract individual components\n",
    "                return extract_json_components(json_str)\n",
    "                \n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Failed to parse JSON from this raw output: {response_text}\")\n",
    "\n",
    "def extract_json_components(json_str):\n",
    "    \"\"\"Extract JSON components manually as fallback\"\"\"\n",
    "    import re\n",
    "    \n",
    "    # Extract subject (using raw string)\n",
    "    subject_match = re.search(r'\"subject\":\\s*\"([^\"]*)\"', json_str)\n",
    "    subject = subject_match.group(1) if subject_match else \"\"\n",
    "    \n",
    "    # Extract messages array - simplified extraction\n",
    "    messages = []\n",
    "    message_blocks = re.findall(r'\\{[^{}]*\"from\"[^{}]*\\}', json_str, re.DOTALL)\n",
    "    \n",
    "    for block in message_blocks:\n",
    "        message = {}\n",
    "        \n",
    "        # Extract each field with regex (using raw strings with rf prefix for f-strings)\n",
    "        for field in ['from', 'to', 'timestamp_raw', 'timestamp_iso', 'document_id']:\n",
    "            match = re.search(rf'\"{field}\":\\s*\"([^\"]*)\"', block)\n",
    "            message[field] = match.group(1) if match else \"\"\n",
    "        \n",
    "        # Handle message_html separately (might contain quotes)\n",
    "        html_match = re.search(r'\"message_html\":\\s*\"(.*?)\"(?=\\s*[,}])', block, re.DOTALL)\n",
    "        message['message_html'] = html_match.group(1) if html_match else \"\"\n",
    "        \n",
    "        # Handle other_recipients array\n",
    "        recipients_match = re.search(r'\"other_recipients\":\\s*\\[(.*?)\\]', block)\n",
    "        if recipients_match:\n",
    "            recipients_str = recipients_match.group(1)\n",
    "            message['other_recipients'] = re.findall(r'\"([^\"]*)\"', recipients_str)\n",
    "        else:\n",
    "            message['other_recipients'] = []\n",
    "            \n",
    "        messages.append(message)\n",
    "    \n",
    "    return {\n",
    "        \"subject\": subject,\n",
    "        \"messages\": messages\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"JSON cleaning functions defined\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "from typing import Optional, Dict, Any\n",
    "\n",
    "def clean_and_extract_json_qwen3(raw_text: str) -> Optional[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Attempts to clean non-JSON artifacts (like markdown fences or preamble text)\n",
    "    from the LLM's raw response and load the JSON object.\n",
    "    \n",
    "    Args:\n",
    "        raw_text: The complete string response from the LLM.\n",
    "    \n",
    "    Returns:\n",
    "        The parsed Python dictionary, or None if parsing fails.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Remove markdown code fences and unnecessary backticks\n",
    "    # This targets \"```json ... ```\" or \"``` ... ```\"\n",
    "    text = re.sub(r'```json\\s*|```\\s*', '', raw_text, flags=re.IGNORECASE)\n",
    "    \n",
    "    # 2. Trim leading/trailing whitespace and non-JSON characters\n",
    "    # Look for the first '{' and the last '}'\n",
    "    start_match = re.search(r'^\\s*\\{', text, re.DOTALL)\n",
    "    end_match = re.search(r'\\}\\s*$', text, re.DOTALL)\n",
    "\n",
    "    if start_match and end_match:\n",
    "        # Get the clean content between the first '{' and the last '}'\n",
    "        start_index = start_match.start() + start_match.group().find('{')\n",
    "        end_index = end_match.end() - end_match.group()[::-1].find('}') # Finds the last '}'\n",
    "        \n",
    "        cleaned_json_string = text[start_index : end_index + 1].strip()\n",
    "        \n",
    "        try:\n",
    "            # 3. Attempt to load the cleaned string\n",
    "            return json.loads(cleaned_json_string)\n",
    "        except json.JSONDecodeError:\n",
    "            # If the JSON structure itself is invalid (e.g., missing comma)\n",
    "            return None\n",
    "    \n",
    "    # If no valid JSON structure ({} block) was found\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML cleaning function defined\n"
     ]
    }
   ],
   "source": [
    "# Helper function to clean HTML for comparison\n",
    "def clean_html_for_comparison(html_text):\n",
    "    \"\"\"Remove HTML tags and normalize whitespace for comparison\"\"\"\n",
    "    # Remove HTML tags\n",
    "    text = re.sub(r'<[^>]+>', '', html_text)\n",
    "    # Normalize whitespace (collapse multiple spaces/newlines into single spaces)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text.strip()\n",
    "\n",
    "print(\"HTML cleaning function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt defined\n"
     ]
    }
   ],
   "source": [
    "EXTRACTION_PROMPT = \"\"\"# TASK\n",
    "Extract all single messages from this email thread in JSON format:\n",
    "{{\n",
    "  \"subject\": \"Email subject\",\n",
    "  \"messages\": [{{\n",
    "    \"from\": \"Sender\",\n",
    "    \"to\": \"Recipient\",\n",
    "    \"other_recipients\": [\"Others except Jeffrey Epstein/jeevacation@gmail.com\"],\n",
    "    \"timestamp_raw\": \"As shown\",\n",
    "    \"timestamp_iso\": \"yyyymmddhhmmss format\",\n",
    "    \"message_html\": \"complete HTML content of this message excluding: quoted text or signatures or disclaimers\",\n",
    "    \"document_id\": \"HOUSE_OVERSIGHT_XXXXXX from bottom page corner\"\n",
    "  }}]\n",
    "}}\n",
    "Special instructions:\n",
    "* If the message is quoted text, the recipient is the one receiving the quoted text, which is the message above.\n",
    "* Return only valid JSON.\n",
    "* document_id must be extracted from the bottom corner of the page image. Replace the X's with the actual number.\n",
    "* the \"from or \"to\" can be partial names\n",
    "* if the \"from or \"to\" are completely missing you must return <REDACTED> instead\n",
    "# Here is raw text from the email thread by OCR:\n",
    "{ocr_text}\n",
    "# Here are the images of the same email thread:\n",
    "\"\"\"\n",
    "print(\"Prompt defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's try a more advanced prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXTRACTION_PROMPT = \"\"\"\n",
    "# INSTRUCTIONS FOR DATA EXTRACTION\n",
    "You are a highly accurate email forensics expert. Your task is to analyze the provided OCR text and image content of an email thread and extract every distinct, non-quoted message into a single JSON object.\n",
    "\n",
    "## JSON SCHEMA REQUIREMENT\n",
    "You MUST return ONLY a single, valid JSON object following this strict schema. Do NOT include any text, markdown fences (```json), or explanation outside of the JSON object.\n",
    "\n",
    "{{\"subject\":\"Email subject of the thread\",\"messages\":[{{\"from\":\"Sender Name/Email (Use <REDACTED> if missing)\",\"to\":\"Primary Recipient Name/Email (Use <REDACTED> if missing)\",\"other_recipients\":[\"List of CC/BCC names (Exclude Jeffrey Epstein/jeevacation@gmail.com)\"],\"timestamp_raw\":\"Date and Time exactly as shown in the header\",\"timestamp_iso\":\"Convert timestamp strictly to YYYYMMDDHHMMSS format. If time is missing, use 000000.\",\"message_html\":\"The complete HTML content of this single, distinct message body. Strip all quoted replies, signatures, and disclaimers.\",\"document_id\":\"Extract the page ID where the message is found (format: HOUSE_OVERSIGHT_XXXXXX).\"}}]}}\n",
    "\n",
    "## EXTRACTION RULES\n",
    "1.  **Thread Unrolling:** Treat each distinct email reply as a separate object in the 'messages' array. Messages should be ordered chronologically (oldest to newest).\n",
    "2.  **Multimodality:** Use the **OCR Text** for the body content and the **Images** for layout verification and locating the **Document ID** in the footer.\n",
    "3.  **Redaction:** If the 'from' or 'to' fields are incomplete or missing, return <REDACTED>.\n",
    "4.  **Output Format:** **STRICTLY RETURN ONLY THE JSON OBJECT.**\n",
    "\n",
    "# INPUT DATA\n",
    "## OCR Text:\n",
    "{ocr_text}\n",
    "## Images:\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API and Database Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Functions defined\n"
     ]
    }
   ],
   "source": [
    "def process_email_with_vision(text_content, image_base64_list):\n",
    "    try:\n",
    "        prompt = EXTRACTION_PROMPT.format(ocr_text=text_content)\n",
    "        content = [{\"type\": \"text\", \"text\": prompt}]\n",
    "        for img_base64 in image_base64_list:\n",
    "            content.append({\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{img_base64}\"}})\n",
    "        response = client.chat.completions.create(\n",
    "            model=OPENAI_API_MODEL,\n",
    "            messages=[{\"role\": \"user\", \"content\": content}],\n",
    "            # temperature=0.02,\n",
    "            max_tokens=8000,\n",
    "        )\n",
    "        #print the complete response for debugging\n",
    "        # print(response)\n",
    "        response_text = response.choices[0].message.content.strip()\n",
    "        \n",
    "        # Use the robust JSON cleaning function\n",
    "        parsed_json = clean_and_extract_json_qwen3(response_text)\n",
    "\n",
    "        # If parsing failed, log the raw response for debugging\n",
    "        if parsed_json is None:\n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(f\"FAILED TO PARSE JSON - RAW RESPONSE:\")\n",
    "            print(f\"{'='*60}\")\n",
    "            print(response_text)\n",
    "            print(f\"{'='*60}\\n\")\n",
    "            return None, f\"JSON parsing failed\"\n",
    "        \n",
    "        return parsed_json, None\n",
    "        \n",
    "    except Exception as e:\n",
    "        # More detailed error reporting\n",
    "        error_msg = f\"API/Parsing error: {str(e)}\"\n",
    "        if \"response_text\" in locals():\n",
    "            error_msg += f\" | Response preview: {response_text[:200]}...\"\n",
    "        return None, error_msg\n",
    "\n",
    "def save_email_to_database(filename, num_pages, file_size_kb, extracted_data):\n",
    "    \"\"\"Thread-safe database write function\"\"\"\n",
    "    with db_lock:  # Ensure only one thread writes at a time\n",
    "        conn = sqlite3.connect(DB_PATH)\n",
    "        cursor = conn.cursor()\n",
    "        try:\n",
    "            subject = extracted_data.get('subject', '')\n",
    "            cursor.execute('INSERT INTO email_documents (filename, subject, num_pages, file_size_kb, processing_status) VALUES (?, ?, ?, ?, ?)',\n",
    "                          (filename, subject, num_pages, file_size_kb, 'success'))\n",
    "            email_doc_id = cursor.lastrowid\n",
    "            for idx, message in enumerate(extracted_data.get('messages', [])):\n",
    "                cursor.execute('INSERT INTO messages (email_document_id, source_filename, subject, message_order, from_address, to_address, other_recipients, timestamp_raw, timestamp_iso, message_html, document_id) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)',\n",
    "                              (email_doc_id, filename, subject, idx, message.get('from', ''), message.get('to', ''), json.dumps(message.get('other_recipients', [])),\n",
    "                               message.get('timestamp_raw', ''), message.get('timestamp_iso', ''), message.get('message_html', ''), message.get('document_id', '')))\n",
    "            conn.commit()\n",
    "            return True, None\n",
    "        except Exception as e:\n",
    "            conn.rollback()\n",
    "            return False, str(e)\n",
    "        finally:\n",
    "            conn.close()\n",
    "\n",
    "def mark_email_failed(filename, error_message):\n",
    "    \"\"\"Thread-safe failure marking function\"\"\"\n",
    "    with db_lock:\n",
    "        conn = sqlite3.connect(DB_PATH)\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute('INSERT OR REPLACE INTO email_documents (filename, processing_status, error_message) VALUES (?, ?, ?)',\n",
    "                      (filename, 'failed', error_message))\n",
    "        conn.commit()\n",
    "        conn.close()\n",
    "\n",
    "print(\"Functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        page_number    num_pages  file_size_kb\n",
      "count   2112.000000  2112.000000   2112.000000\n",
      "mean   29700.258523     2.807292      4.428660\n",
      "std     3996.217631     5.086675      9.436321\n",
      "min    11277.000000     1.000000      0.160000\n",
      "25%    27048.750000     1.000000      1.110000\n",
      "50%    31003.500000     2.000000      2.275000\n",
      "75%    32671.250000     3.000000      4.575000\n",
      "max    33599.000000   149.000000    290.130000\n"
     ]
    }
   ],
   "source": [
    "## show statistics of emails_df, such as average number of pages, total size, etc.\n",
    "emails_df = pd.read_csv('emails_list.csv')\n",
    "print(emails_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Processing Loop (Parallelized with 20 Threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1951 emails with 20 parallel threads\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing emails:  30%|██▉       | 577/1951 [20:59<22:50,  1.00it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "FAILED TO PARSE JSON - RAW RESPONSE:\n",
      "============================================================\n",
      "{\n",
      "    \"subject\": \"time to publish this instead ofthe trite.\",\n",
      "    \"messages\": [\n",
      "        {\n",
      "            \"from\": \"jeffrey E. [jeevacation@gmail.com]\",\n",
      "            \"to\": \"Mortimer Zuckerman\",\n",
      "            \"other_recipients\": [],\n",
      "            \"timestamp_raw\": \"2/10/2015 5:22:52 PM\",\n",
      "            \"timestamp_iso\": \"20150210172252\",\n",
      "            \"message_html\": \"<p>Fwd: Statement for Press</p>\",\n",
      "            \"document_id\": \"HOUSE_OVERSIGHT_029225\"\n",
      "        },\n",
      "        {\n",
      "            \"from\": \"Carolyn Cohen\",\n",
      "            \"to\": \"Alan Dershowitz\",\n",
      "            \"other_recipients\": [],\n",
      "            \"timestamp_raw\": \"February 10, 2015 at 10:40:57 AM EST\",\n",
      "            \"timestamp_iso\": \"20150210104057\",\n",
      "            \"message_html\": \"<p>Alan Dershowitz's Statement: We can now prove that Jane Doe #3 has no credibility and lied about Clinton, the Gores and Dershowitz.</p><p>Dershowitz's lawyers have filed a detailed reply to Jane Doe #3 false charges. In it they definitively respond to all of the alleged evidence presented by Jane Doe #3 and her lawyers. Since that filing Mr. Dershowitz's lawyers have uncovered additional evidence that Jane Doe #3 has lied about her alleged contacts with former President Clinton and former Vice President Gore and the then Mrs. Gore. In her first affidavit to the court she repeats the claim that she had earlier sold to a British tabloid: namely that \\\"former President Bill Clinton was present on the island [Jeffrey Epstein's private island] at a time when [Jane Doe #3] was also present on the Island.\\\"</p><p>This statement, sworn under oath, summarizes a far more elaborate fantasy that she sold to a British tabloid which has since been repeated by the international media. In neither statement, does she provide any specific dates or times, but she does weave an imaginative fantasy about her fictional meeting with former President Clinton. She \\\"describes\\\" how Mr. Clinton's Secret Service detail allowed Ghislaine Maxwell, then a novice helicopter pilot, to fly the former President to Epstein's private island on a large black helicopter — an obvious lie. She then purports to \\\"describe\\\" specific seating locations at a fictional dinner party that included her, Mr. Clinton, Jeffrey Epstein and two other underage \\\"olive-skinned brunettes\\\" whose identities she could not provide:</p><p>I flew to the Caribbean with Jeffrey and then Ghislaine Maxwell went to pick up Bill in a huge black helicopter that Jeffrey had bought her. She'd always wanted to fly and Jeffrey paid for her to take lessons, and I remember she was very excited because she got her licence around the first year we met. I used to get frightened flying with her but Bill had the Secret Service with him and I remember him talking about what a good job she did. I only ever met Bill twice but Jeffrey had told me that they were good friends. I asked, \\\"How come?\\\" and he laughed and said, \\\"He owes me some favours.\\\" Maybe he was just joking but it constantly surprised me that people with as much to lose as Bill and [Prince] Andrew weren't more careful. She said that when dining that night, Maxwell sat at President Clinton's left, while they were joined by two 'olive-skinned brunettes' who had been flown in from New York...</p><p>I'd never met them before. I'd say they were no older than 17, very innocent-looking. They weren't there for me. They weren't there for Jeffrey or Ghislaine because I was there to have sex with Jeffrey on the trip.</p><p>Maybe Jeffrey thought they would entertain Bill, but I saw no evidence that he was interested in them. He and Jeffrey and Ghislaine seemed to have a very good relationship. Bill was very funny. He made me laugh a few times. And he and Jeffrey and Ghislaine told blokey jokes and the brunettes listened politely and giggled.</p><p>After dinner I gave Jeffrey an erotic massage. I don't remember seeing Bill again on the trip but I assume Ghislaine flew him back...</p><p>Jane Doe #3 also concocted another meeting with a powerful political figure for the British tabloid, this time claiming to have met former Vice President Gore and his then wife, Tipper, on the same Island, again providing no specific dates or times, but only personal interest details designed to enhance the value of her fictional account</p><p>[Jane Doe #3} disclosed that Mr Clinton's vice-president Al Gore and his wife, Tipper, were also guests of Epstein on his island... 'I had no clue that anything was up,' [Jane Doe #3] says. 'The Gores seemed like a beautiful couple when I met them. All I knew was that Mr Gore was a friend of Jeffrey's and Ghislaine's. Jeffrey didn't ask me to give him a massage... There might have been a couple of other girls there on that trip but I could never have imagined this guy would do anything wrong. I was planning to vote for him when I turned 18. I thought he was awesome.\"</p><p>These fabrications, which are obvious on their face, could easily have been determined to be false by any reasonable investigation. Our investigation has turned up evidence that Mr. Clinton was never on Mr. Epstein's island, that neither Mr. Gore, nor his former wife, have ever been on the island, and that Mr. and Mrs. Gore do not even know Mr. Epstein. Jane Doe #3's salaciously detailed accounts, sold for money to a tabloid are made up and were purposely designed to titillate the interests of readers eager for such salacious material. Jane Doe #3's even more salacious \\\"descriptions\\\" of her alleged sexual encounters with Dershowitz are also fabricated.</p><p>If it turns out that Jane Doe #3 deliberately lied about seeing former President Clinton on the island, she would be guilty of perjury.</p><p>Mr. Dershowitz's legal team has uncovered additional evidence, which it is in the process of verifying, that proves a pattern of lying and false accusations that casts even further doubt on Jane Doe #3's credibility. This evidence will be disclosed once it has been confirmed by their investigation.</p>\",\n",
      "            \"document_id\": \"HOUSE_OVERSIGHT_029226\"\n",
      "        },\n",
      "        {\n",
      "            \"from\": \"Alan Dershowitz\",\n",
      "            \"to\": \"Darren, me, Martin\",\n",
      "            \"other_recipients\": [],\n",
      "            \"timestamp_raw\": \"11:46 AM (1 hour ago)\",\n",
      "            \"timestamp_iso\": \"20150210114600\",\n",
      "            \"message_html\": \"<p>please note</p><p>The information contained in this communication is confidential, may be attorney-client privileged, may constitute inside information, and is intended only for the use of the addressee. It is the property of JEE Unauthorized use, disclosure or copying of this communication or any part thereof is strictly prohibited and may be unlawful. If you have received this communication in error, please notify us immediately by return e-mail or by e-mail to jeevacation@gmail.com, and destroy this communication and all copies thereof, including all attachments. copyright -all rights reserved</p>\",\n",
      "            \"document_id\": \"HOUSE_OVERSIGHT_029227\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "============================================================\n",
      "\n",
      "❌ HOUSE_OVERSIGHT_029225.txt: JSON parsing failed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing emails:  37%|███▋      | 713/1951 [26:12<1:22:43,  4.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "FAILED TO PARSE JSON - RAW RESPONSE:\n",
      "============================================================\n",
      "{\n",
      "    \"subject\": \"Re: Keating Interview\",\n",
      "    \"messages\": [\n",
      "        {\n",
      "            \"from\": \"jeffrey epstein [jeevacation@gmail.com]\",\n",
      "            \"to\": \"Katherine Keating\",\n",
      "            \"other_recipients\": [],\n",
      "            \"timestamp_raw\": \"10/28/2011 4:32:02 PM\",\n",
      "            \"timestamp_iso\": \"20111028163202\",\n",
      "            \"message_html\": \"<p>Are you here</p><p>Sorry for all the typos .Sent from my iPhone</p>\",\n",
      "            \"document_id\": \"HOUSE_OVERSIGHT_029658\"\n",
      "        },\n",
      "        {\n",
      "            \"from\": \"<REDACTED>\",\n",
      "            \"to\": \"<REDACTED>\",\n",
      "            \"other_recipients\": [],\n",
      "            \"timestamp_raw\": \"Oct 28, 2011, at 12:36 AM\",\n",
      "            \"timestamp_iso\": \"20111028003600\",\n",
      "            \"message_html\": \"<p>Paul Keating explains as never before</p><ul><li>BY:PAUL KELLY, EDITOR-AT-LARGE</li><li>From:The Australian</li><li>October 22, 2011 12:00AM</li></ul><p>http://www.theaustralian.com.au/news/features/paul-keating-explains-as-never-before/story-e6fro6z6-1226173493029&amp;ct=ga&amp;cad=CAcQAhgAIAAoATAA0ABAkPKI9QRIAVAAWABiBVVVuLVVT&amp;cd=JW8oA0ivUQM&amp;usg=AFQjCNHdOmUbAjc-21iiig3exEbZmRt2w</p><p>WITH his panoramic view of world affairs sharper than ever, Paul Keating blames the current global crisis on blunders by European and US leaders and warns that Australia must rediscover the keys to national success.</p><p>Interviewed in his Sydney office, furnished in a style he calls \\\"the last gasp of revolutionary classicism\\\", Keating's new 600-plus page book sits atop his desk, an insight into his intellectual, aesthetic and political obsessions.</p><p>What has Keating been doing since he left office in 1996? He has been travelling, speaking and analysing the world and Australia with undiminished intensity suggesting a man operating as prime minister-in-exile.</p><p>His idea of leadership is more philosophical than ever, more distant from Bob Hawke or John Howard. His focus is the synthesis between beauty and reason and his book encompasses China's currency, the world malaise, Mahler's Symphony No2 and breaking the republic with the Queen.</p><p>DURING THE INTERVIEW KEATING TALKS, AS NEVER BEFORE, ABOUT HIS LEADERSHIP CONCEPT. BUT HE IS DOING SOMETHING ELSE: EXPLAINING HIMSELF TO A STILL PUZZLED NATION.RECOMMENDED COVERAGE</p><p>Creativity is central to our endeavours</p><p>The great changes in civilisation and society have been wrought by deeply held beliefs and passion rather than by a process of rational deduction,</p><p>Keating tells me. In retirement, his political inspiration comes from music and beauty, not opinion polls.</p><p>There are signs he has mellowed. While ruthless with his judgments Keating is keen to support a struggling Labor Party while addressing the source of its strategic demise.</p><p>The failure of the Rudd and Gillard administrations is the lack of an over-arching story, the lack of a compelling story,</p><p>he says when interviewed last week.</p><p>I'm happy that Labor took us through this dreadful financial crisis so competently. But they are not in the business of teaching. And governments, to succeed with change, must be in the business of educating the community.</p><p>Our Labor governments have failed to conceptualise the changes. We need a framework.</p><p>What is the framework? It is 'Australia in Transition' strategically and economically. That's the story we have to present.</p><p>I think the Australian people are very conscientious. During the 1980s and 1990s we proved they will respond conscientiously to necessary reforms. They mightn't like them but they'll accept them. But reforms have to be presented in a digestible format.</p><p>I know that in the age of the internet, opinion and perpetual static it is difficult to get the message over. I accept that. But the big messages have their own momentum. If we get the story of transition right then other things will find their place.</p><p>Our problem is what I call shooting-star policies. We have a policy on carbon pricing, on minerals, on boatpeople, but they are not connected up to the big picture about Australia's direction and its transition.</p><p>Pressed on whether he thinks the Australian Labor Party is in permanent decline, Keating defends Labor, insists it doesn't have to decline but highlights the problem. \\\"Labor must recognise what it has created,\\\" he says, invoking the Hawke-Keating era. \\\"It has a created a new society and it has to be the party of the new society.</p><p>It can't be the party of part of the old society. Labor must be the party of those people who gained from the pro-market growth economy that we created. Labor must be open to the influences of this middle class, to people on higher incomes. And I don't think it is.</p><p>It is, perhaps, the clearest statement of Labor's problem. The party, in an act of strategic folly, abandoned the path of its previous success. It turned inwards on itself, away from the community.</p><p>At the operating level it's become the party of insiders,</p><p>Keating says. \\\"The problem is that members get too caught up in the gift of faction managers and they get caught up in the false construct of popularity, the false god.\\\"</p><p>Fixated by the nature of political leadership, Keating's book After Words shouts out: \\\"The great curse of modern political life is incrementalism.\\\"</p><p>Leaning across the table he says to me that briefing notes and economic texts aren't enough: the leader must locate his own source of higher command and inner belief. He laments the efforts of US President Barak Obama and German Chancellor Angela Merkel in the teeth of contemporary challenges.</p><p>There is nothing preordained about American decline any more than the European project is destined to fail,</p><p>he writes.</p><p>But the portents are not good. Despite the rhetoric, President Obama conducts himself as an arbitrator or mediator between the competing strands of American economic and political ideology. He repeatedly eschews striking out,</p><p>snatching the naked flame and hanging on. But the cost of this strategy is not simply a cost to him; it is a cost to the whole world.</p><p>On the other hand, Chancellor Merkel is the archetypal worry-wart. She does not lead; she assesses.</p><p>You really wonder why leaders want these jobs when they really do not want to lead. And what is their risk? That Barack Obama will not get a second term? Or that Angela Merkel's coalition might finally end up on the rocks? If they actually made the leap they might astound themselves. Because, in the end, everyone in political life gets carried out - the only relevant question is whether the pallbearers will be crying.</p><p>For Keating, the 20th-century leader exerting most influence on the coming century is China's Deng Xiaoping.</p><p>If you look at the other figures of the century, Roosevelt, Churchill, Stalin and Mao, none will leave the legacy in terms of the 21st century that Deng leaves,</p><p>he says. \\\"He walked away from the ideology of the Communist Party just as effectively as Mikhail Gorbachev walked away from the essence of the Soviet Union.\\\"</p><p>By 2050 Keating sees a world order with nations in terms of gross domestic product in this hierarchy: (1) China, (2) US, (3) India, (4) Japan, (5) Brazil, (6) Russia, (7) Britain, (8) Germany, (9) France and (10) Italy.</p><p>The key, however, is that Japan lags a distant fourth behind the top three.</p><p>On America, Keating is dismayed by the pivotal change in its outlook after the end of the Cold War. \\\"When the Berlin Wall came down the Americans cried victory and walked off the field,\\</p><p>he says.</p><p>Yet the end of the Cold War offered the chance for America to develop a new world order. It didn't know what to do with its victory. This at the moment the US should have begun exploiting the opportunity of establishing a new world order to embrace open regionalism and the inclusion of great states like China, India and the then loitering Russia.</p><p>Well, frankly, the US didn't have the wisdom. It just wanted to celebrate its peace dividend. The two Clinton terms and the two George W. Bush terms, that's four presidential terms, have cost US mightily.</p><p>For Keating, the malaise in US politics is the problem. He says: \\\"The most compelling thing I've seen in years is that in the great burst of American productivity between 1990 and 2008, of that massive increment to national income, none of it went to wages. By contrast, in Australia real wages over the same period had risen by 30 per cent.\\\"</p><p>Keating sees this \\\"as the breakdown of America's national compact\\\", the shattering of its prosperity deal. He says American conservatives abandoned the middle ground represented by Republican presidents such as Dwight D. Eisenhower, Richard Nixon and Bush Sr and became radicals. The derailment, he argues, began under Ronald Reagan and reached its zenith under George W. Bush.</p><p>With the goodwill gone the US \\\"is not able to produce a medium-term credible fiscal trajectory or get agreement on rebuilding its infrastructure\\\". This paralysis \\\"is significant not just for the US but for the world.\\\"</p><p>Keating links the collapse of this \\\"prosperity compact\\\" to the financial crisis. Too many Americans were unable to sustain themselves from wages and salaries.</p><p>How did they get by? They used the easy credit of the banking system, thereby feeding the frenzy that ended in bad loans and meltdown.</p><p>Keating's book has an abiding message for Australia: in the transformed world we \\\"will find ourselves increasingly on our own\\\" having to master our own destiny.</p><p>The job is to rediscover the productivity and savings agenda of the 1990s. Why did Australia survive the 2008 financial crisis? \\\"Because of the flexibility of the economy,\\</p><p>Keating says. \\\"Flexibility which came from the reform of Australia's financial, product and labour markets that began 25 years ago. This has given us one of the most flexible economies in the world - arguably the most flexible. But further structural changes are ahead of us.</p><p>He lists them. It is a mix of the new and old Keating agenda: a shift in resources to the extractive industries; a lift in capital inflow driving a high current account deficit putting a premium on savings; recognition that competitiveness will lie \\\"in the creativity of our people as much as it does in our oil and gas\\\"; a renewed emphasis on the value of hi-tech and education; and above all, a cultural change that integrates Australia more into East Asia. \\\"Cultural transformation is the key for us,\\</p><p>Keating says. He rates it as more important than economic reform.</p><p>There is less interest now in being part of East Asia than there was in the 1990s,</p><p>he laments.</p><p>Keating wants this idea revived. And he ties it to the republic arguing that to succeed in Asia we must become a republic, a proposition Howard always dismissed.</p><p>On China, Keating is an optimist yet alive to the daunting economic challenge China now confronts. \\\"What is happening in China knows no precedence in world economic history,\\</p><p>he says. \\\"Never before have 1.25 billion people dragged themselves from poverty at such a pace. China is now half the GDP of the US and incomes have risen by a factor of 10.\\\" He argues, however, that the origin of the 2008 financial crisis lies in the global imbalances - China has built huge foreign exchange reserves by exporting too much and America, in turn, is saving too little.</p><p>Keating says: \\\"China must shift the basis of growth from net exports and investment to domestic consumption. Will they achieve this? Probably. Will there be strains along the way? There have to be.</p><p>Unlike many Australian leaders, Keating is a Europhile. \\\"I think the European project is the most significant project since the second world war,\\</p><p>he says. But he sees two huge blunders made in Europe.</p><p>From the euro's inception, Keating said it should constitute only Germany, France and the Benelux nations, not the peripheral countries around the Mediterranean, and \\\"Greece should never have been allowed in\\\".</p><p>Why were the weaker economies given entry?</p><p>Keating says: \\\"It's because president Mitterrand and the French wanted it. They weren't ready to sit beside the German unified state without some friends.</p><p>So the eurozone was flawed from the outset, a structure awaiting internal assault: \\\"The problem is we have a single currency without a political union and without a fiscal union.</p><p>The second blunder was the 1990s expansion of NATO to the Russian border. For Keating, this was recklessness for which the world may yet pay.</p><p>Sensible policy would have included a place for Russia in the new world order,</p><p>he says. \\\"But that didn't happen. So Russian liberals were pushed to one side by Russian nationalists. In a sense the US has created Vladimir Putin.</p><p>Who is responsible? He points the finger at Bill Clinton.</p><p>On the 2008 financial crisis, he says former US Federal Reserve chief Alan Greenspan must bear \\\"a fair amount of responsibility\\\".</p><p>\\\"Greenspan is someone I know and like,\\</p><p>Keating says. \\\"But if you are so naive to believe that institutions with a balance sheet with assets geared at 45 to one is not an accident waiting to happen then you don't deserve to be chairman of the Federal Reserve.</p><p>He praises Obama for seeking a return to the \\\"liberal internationalism\\\" that, in Keating's view, made the US great in the post-World War II age. This is the US he loves but it is still in retreat.</p><p>Asked about the nature of leadership, Keating reveals what lies within his heart: \\\"I believe there is a poetic strand to life that doesn't exist in an economics textbook.</p><p>This is not to say that rationalism isn't important and good. It is. But left to itself without the guidance of higher meaning and a higher concept, rationalism can be mean and incomplete. I say if you simply live on rational policy and briefing notes you are not sufficiently informed.</p><p>You need a higher calling or some inner system of belief - here I mention Kant and the inner command that tells you what is true, what is right, what is good. The inner command must be the divining construct in what you do.</p><p>Music has always been a large part of what makes me tick. You listen to a great work ... you hear the majesty of these works and your head and soul gets caught up in them. When that happens you are in for bigger things and you will strike out to be better.</p><p>When I was listening to music I would always have the pad out to write the ideas down.</p>\",\n",
      "            \"document_id\": \"HOUSE_OVERSIGHT_029659\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "============================================================\n",
      "\n",
      "❌ HOUSE_OVERSIGHT_029658.txt: JSON parsing failed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing emails:  84%|████████▍ | 1647/1951 [52:46<06:26,  1.27s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ HOUSE_OVERSIGHT_029773.txt: API/Parsing error: Request timed out.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing emails: 100%|██████████| 1951/1951 [58:05<00:00,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def process_single_email(row):\n",
    "    \"\"\"Worker function to process a single email\"\"\"\n",
    "    filename = row['filename']\n",
    "    result_data = {\n",
    "        'filename': filename,\n",
    "        'num_pages': row['num_pages'],\n",
    "        'success': False,\n",
    "        'error': None,\n",
    "        'num_messages': 0,\n",
    "        'subject': None\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Find text file\n",
    "        text_path = get_text_file_path(filename)\n",
    "        if not text_path:\n",
    "            raise FileNotFoundError(f\"Could not find {filename}\")\n",
    "        \n",
    "        with open(text_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "            text_content = f.read()\n",
    "        \n",
    "        # Get and encode images\n",
    "        image_paths = get_image_paths(row['page_number'], row['num_pages'])\n",
    "        image_base64_list = [resize_and_encode_image(p) for p in image_paths if resize_and_encode_image(p)]\n",
    "        \n",
    "        # Call API\n",
    "        api_result, error = process_email_with_vision(text_content, image_base64_list)\n",
    "        if error:\n",
    "            result_data['error'] = error\n",
    "            mark_email_failed(filename, error)\n",
    "            return result_data\n",
    "\n",
    "        # Check if parsing completely failed (api_result is None)\n",
    "        if api_result is None:\n",
    "            result_data['error'] = \"JSON parsing failed - no valid data extracted\"\n",
    "            mark_email_failed(filename, \"JSON parsing failed - no valid data extracted\")\n",
    "            return result_data\n",
    "\n",
    "        # Save to database\n",
    "        success, db_error = save_email_to_database(filename, row['num_pages'], row['file_size_kb'], api_result)\n",
    "        if success:\n",
    "            result_data['success'] = True\n",
    "            result_data['num_messages'] = len(api_result.get('messages', []))\n",
    "            result_data['subject'] = api_result.get('subject', 'N/A')[:60]\n",
    "        else:\n",
    "            result_data['error'] = f\"DB error: {db_error}\"\n",
    "            \n",
    "    except Exception as e:\n",
    "        result_data['error'] = str(e)\n",
    "        mark_email_failed(filename, str(e))\n",
    "    \n",
    "    return result_data\n",
    "\n",
    "# Main processing with ThreadPoolExecutor\n",
    "emails_df = pd.read_csv('emails_list.csv')\n",
    "emails_filtered = emails_df[emails_df['num_pages'] <= 5].copy()\n",
    "emails_to_process = emails_filtered  # emails_filtered.head(5) for testing\n",
    "\n",
    "print(f\"Processing {len(emails_to_process)} emails with 20 parallel threads\\n\")\n",
    "\n",
    "# Process emails in parallel with progress bar\n",
    "with ThreadPoolExecutor(max_workers=20) as executor:\n",
    "    # Submit all tasks\n",
    "    futures = {executor.submit(process_single_email, row): idx for idx, row in emails_to_process.iterrows()}\n",
    "    \n",
    "    # Process results as they complete with progress bar\n",
    "    for future in tqdm(as_completed(futures), total=len(futures), desc=\"Processing emails\"):\n",
    "        result = future.result()\n",
    "        \n",
    "        # Optional: print individual results (can be commented out for cleaner output)\n",
    "        if not result['success']:\n",
    "            # tqdm.write(f\"✓ {result['filename']}: {result['num_messages']} messages - {result['subject']}\")\n",
    "            tqdm.write(f\"❌ {result['filename']}: {result['error']}\")\n",
    "\n",
    "print(\"\\nProcessing complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>processing_status</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>failed</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>success</td>\n",
       "      <td>1948</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  processing_status  count\n",
       "0            failed      3\n",
       "1           success   1948"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed Emails (1948):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>subject</th>\n",
       "      <th>num_pages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOUSE_OVERSIGHT_033561.txt</td>\n",
       "      <td>Fwd: Why Palm Beach, Florida Is The 'New Green...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOUSE_OVERSIGHT_033498.txt</td>\n",
       "      <td>RE: Jane Doe</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOUSE_OVERSIGHT_033589.txt</td>\n",
       "      <td>Fwd: Patterson</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOUSE_OVERSIGHT_033508.txt</td>\n",
       "      <td>RE: Jane Doe</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOUSE_OVERSIGHT_033596.txt</td>\n",
       "      <td>Gulfstream V - offmarket, sleeper aircraft</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1943</th>\n",
       "      <td>HOUSE_OVERSIGHT_016692.txt</td>\n",
       "      <td>Russian House</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1944</th>\n",
       "      <td>HOUSE_OVERSIGHT_011907.txt</td>\n",
       "      <td>RE:</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1945</th>\n",
       "      <td>HOUSE_OVERSIGHT_014516.txt</td>\n",
       "      <td>Fwd: 2016 Election: Tax Changes Expected</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1946</th>\n",
       "      <td>HOUSE_OVERSIGHT_012898.txt</td>\n",
       "      <td>Farmer Jaffe is suing Donald Trump!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1947</th>\n",
       "      <td>HOUSE_OVERSIGHT_012102.txt</td>\n",
       "      <td>Email subject of the thread</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1948 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        filename  \\\n",
       "0     HOUSE_OVERSIGHT_033561.txt   \n",
       "1     HOUSE_OVERSIGHT_033498.txt   \n",
       "2     HOUSE_OVERSIGHT_033589.txt   \n",
       "3     HOUSE_OVERSIGHT_033508.txt   \n",
       "4     HOUSE_OVERSIGHT_033596.txt   \n",
       "...                          ...   \n",
       "1943  HOUSE_OVERSIGHT_016692.txt   \n",
       "1944  HOUSE_OVERSIGHT_011907.txt   \n",
       "1945  HOUSE_OVERSIGHT_014516.txt   \n",
       "1946  HOUSE_OVERSIGHT_012898.txt   \n",
       "1947  HOUSE_OVERSIGHT_012102.txt   \n",
       "\n",
       "                                                subject  num_pages  \n",
       "0     Fwd: Why Palm Beach, Florida Is The 'New Green...          2  \n",
       "1                                          RE: Jane Doe          5  \n",
       "2                                        Fwd: Patterson          2  \n",
       "3                                          RE: Jane Doe          4  \n",
       "4            Gulfstream V - offmarket, sleeper aircraft          3  \n",
       "...                                                 ...        ...  \n",
       "1943                                      Russian House          1  \n",
       "1944                                                RE:          1  \n",
       "1945           Fwd: 2016 Election: Tax Changes Expected          2  \n",
       "1946                Farmer Jaffe is suing Donald Trump!          1  \n",
       "1947                        Email subject of the thread          1  \n",
       "\n",
       "[1948 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "conn = sqlite3.connect(DB_PATH)\n",
    "summary = pd.read_sql_query('SELECT processing_status, COUNT(*) as count FROM email_documents GROUP BY processing_status', conn)\n",
    "print(\"Processing Summary:\")\n",
    "display(summary)\n",
    "\n",
    "emails = pd.read_sql_query('SELECT * FROM email_documents WHERE processing_status=\"success\" ORDER BY processed_at DESC', conn)\n",
    "print(f\"\\nProcessed Emails ({len(emails)}):\")\n",
    "display(emails[['filename', 'subject', 'num_pages']])\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qwen 2.5 VL 72B only one failed\n",
    "Qwen 3 VL qwen3-vl-30b-a3b-instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total messages with 'REDACTED' in from_address or to_address: 4164\n",
      "Total messages in the database: 6577\n"
     ]
    }
   ],
   "source": [
    "# count all messages in the database where from_address or to_address contains 'REDACTED'\n",
    "conn = sqlite3.connect('emails.db')\n",
    "cursor = conn.cursor()\n",
    "cursor.execute('''SELECT COUNT(*) FROM messages WHERE from_address LIKE '%REDACTED%' OR to_address LIKE '%REDACTED%' ''')\n",
    "count = cursor.fetchone()[0]\n",
    "print(f\"Total messages with 'REDACTED' in from_address or to_address: {count}\")\n",
    "# print total number of messages in the database\n",
    "cursor.execute('''SELECT COUNT(*) FROM messages''')\n",
    "total_count = cursor.fetchone()[0]\n",
    "print(f\"Total messages in the database: {total_count}\")\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20251121\n",
    "\n",
    "with qwen 2.5 VL 72B:\n",
    "5 failed messages\n",
    "Total messages with 'REDACTED' in from_address or to_address: 1167\n",
    "Total messages in the database: 4377\n",
    "\n",
    "20251123\n",
    "\n",
    "with qwen 2.5 VL 72B:\n",
    "\n",
    "1 failed messages\n",
    "Total messages with 'REDACTED' in from_address or to_address: 1895\n",
    "Total messages in the database: 6962\n",
    "\n",
    "with x-ai/grok-4.1-fast: \n",
    "30% failed messages -> Failed to parse JSON -> but it seems it is returning much less <REDACTED>\n",
    "\n",
    "20251125\n",
    "\n",
    "Qwen 3 VL qwen3-vl-30b-a3b-instruct: \n",
    "72 failed messages\n",
    "Total messages with 'REDACTED' in from_address or to_address: 648\n",
    "Total messages in the database: 5463\n",
    "with qwen 2.5 VL 72B:\n",
    "Total messages with 'REDACTED' in from_address or to_address: 4164\n",
    "Total messages in the database: 6577"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of messages before cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### display current state of unique addresses across 'from' and 'to'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top Email Addresses:\n",
      "<REDACTED>: 4537\n",
      "jeffrey E. <jeevacation@gmail.com>: 1047\n",
      "jeffrey E. [jeeyacation@gmail.com]: 565\n",
      "jeffrey E. [jeevacation@gmail.com]: 544\n",
      "Weingarten, Reid: 374\n",
      "Michael Wolff: 265\n",
      "Thomas Jr., Landon: 224\n",
      "Jeffrey E.: 208\n",
      "Kathy Ruemmler: 192\n",
      "Jeffrey Epstein [jeevacation@gmail.com]: 158\n",
      "Steve Bannon: 156\n",
      "Nicholas Ribis: 152\n",
      "J <jeevacation@gmail.com>: 145\n",
      "Lawrence Krauss: 144\n",
      "Jeffrey Epstein [jeeyacation@gmail.com]: 137\n",
      "jeevacation@gmail.com: 136\n",
      "Richard Kahn: 127\n",
      "Jeffrey Epstein <jeevacation@gmail.com>: 120\n",
      "jeffrey E.: 120\n",
      "Larry Summers: 98\n",
      "Jessica Cadwell: 87\n",
      "Darren Indyke: 80\n",
      "Jacquie Johnson: 73\n",
      "J [jeevacation@gmail.com]: 67\n",
      "jeffrey E. [mailto:jeevacation@gmail.com]: 66\n",
      "Jeffrey E. <jeevacation@gmail.com>: 66\n",
      "Jeffrey E. [jeeyacation@gmail.com]: 66\n",
      "Jeffrey E. [jeevacation@gmail.com]: 62\n",
      "Boris Nikolic: 55\n",
      "Jeffrey Epstein: 52\n",
      "Larry Visoski: 51\n",
      "Lisa New: 50\n",
      "Rebecca Watson: 49\n",
      "Robert Kuhn: 40\n",
      "Joi Ito: 40\n",
      "Etienne Binant: 40\n",
      "LHS: 39\n",
      "Pritzker, Tom: 36\n",
      "Ken Starr: 35\n",
      "Martin G. Weinberg: 34\n",
      "Jeffrey E. [mailto:jeevacation@gmail.com]: 33\n",
      "Jonathan Farkas: 33\n",
      "Martin Weinberg: 33\n",
      "jeevacation: 32\n",
      "Lesley Groff: 31\n",
      "Barry J. Cohen: 31\n",
      "Jeffrey Epstein [mailto:jeevacation@gmail.com]: 30\n",
      "Deepak Chopra: 30\n",
      "Peggy Siegal: 30\n",
      "J: 29\n",
      "paul krassner: 28\n",
      "Sultan Bin Sulayem: 27\n",
      "Noam Chomsky: 27\n",
      "Tonja Haddad Coleman: 26\n",
      "David Grosof: 26\n",
      "David Stern: 25\n",
      "Alireza Ittihadieh: 25\n",
      "Linda Stone: 23\n",
      "Robert Trivers: 22\n",
      "Boris Nikolic (bgC3): 22\n",
      "Zubair Khan: 19\n",
      "Jay Lefkowitz: 19\n",
      "Richard Merkin: 18\n",
      "J [jeeyacation@gmail.com]: 17\n",
      "Tyler Shears: 17\n",
      "Landon Thomas Jr.: 17\n",
      "Faith Kates: 17\n",
      "Paul Barrett: 17\n",
      "steven hoffenberg: 16\n",
      "David Pegg: 16\n",
      "LHS < >: 16\n",
      "Stanley Rosenberg: 16\n",
      "Michael Wolff < >: 15\n",
      "Ens, Amanda: 15\n",
      "Robert Lawrence Kuhn: 15\n",
      "Eric Roth: 15\n",
      "Masha Drokova: 14\n",
      "Thorbjon Jagland: 14\n",
      "live:linkspirit: 14\n",
      "Melanie Spinella: 14\n",
      "Jeff Epstein <jeevacation@gmail.com>: 14\n",
      "Ingram, David (Reuters News): 13\n",
      "Mark L. Epstein: 13\n",
      "Mohamed Waheed Hassan: 13\n",
      "Christina Galbraith: 13\n",
      "Roy Black: 11\n",
      "Lawrence Krauss <lkrauss@asu.edu>: 11\n",
      "Karp, Brad S: 11\n",
      "Maskin, Eric: 11\n",
      "Lang, Caroline: 11\n",
      "Kevin Frost: 11\n",
      "Jack Goldberger: 11\n",
      "jeffrey epstein [jeevacation@gmail.com]: 11\n",
      "Sharon Churcher: 10\n",
      "Bruce Moskowitz: 10\n",
      "Steven Pfeiffer: 10\n",
      "Miller, Michael: 10\n",
      "Barbro C Ehnbom: 10\n",
      "Peter Thiel: 10\n",
      "Elisa New: 10\n"
     ]
    }
   ],
   "source": [
    "# names can be spelled differently, let's try to make some order in this mess\n",
    "# find all unique from addresses \n",
    "conn = sqlite3.connect(DB_PATH) \n",
    "query = '''\n",
    "SELECT from_address, COUNT(*) as count\n",
    "FROM messages\n",
    "GROUP BY from_address\n",
    "ORDER BY count DESC\n",
    "'''\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(query)\n",
    "results_from = cursor.fetchall()\n",
    "conn.close()\n",
    "# find all unique to addresses \n",
    "conn = sqlite3.connect(DB_PATH) \n",
    "query = '''\n",
    "SELECT to_address, COUNT(*) as count\n",
    "FROM messages\n",
    "GROUP BY to_address\n",
    "ORDER BY count DESC\n",
    "'''\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(query)\n",
    "results_to = cursor.fetchall()\n",
    "conn.close()\n",
    "# add both from and to addresses together and display top 100\n",
    "from collections import defaultdict\n",
    "address_counts = defaultdict(int)\n",
    "for address, count in results_from:\n",
    "    address_counts[address] += count\n",
    "for address, count in results_to:\n",
    "    address_counts[address] += count   \n",
    "results = sorted(address_counts.items(), key=lambda x: x[1], reverse=True) \n",
    "# Display the top results\n",
    "print(\"\\nTop Email Addresses:\")\n",
    "for address, count in results[:100]:\n",
    "    print(f\"{address}: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We replace all From and To values to the value to 'Jeffrey Epstein', if it contains these strings (Consider this in lowercase)\n",
    "# jeffrey e\n",
    "# jeffrey epstein\n",
    "# jeevacation\n",
    "# jeeyacation\n",
    "# also replace when value is just 'J' and message order > 0 (not first in thread) (confer 031103)\n",
    "\n",
    "conn = sqlite3.connect(DB_PATH)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Update from_address\n",
    "update_from_query = '''\n",
    "UPDATE messages\n",
    "SET from_address = 'Jeffrey Epstein'\n",
    "WHERE LOWER(from_address) LIKE '%jeffrey e%'\n",
    "   OR LOWER(from_address) LIKE '%jeffrey epstein%'\n",
    "   OR LOWER(from_address) LIKE '%jeevacation%'\n",
    "   OR LOWER(from_address) LIKE '%jeeyacation%'\n",
    "   OR (from_address = 'J' AND message_order > 0)\n",
    "'''\n",
    "cursor.execute(update_from_query)\n",
    "\n",
    "# Update to_address\n",
    "update_to_query = '''\n",
    "UPDATE messages\n",
    "SET to_address = 'Jeffrey Epstein'\n",
    "WHERE LOWER(to_address) LIKE '%jeffrey e%'\n",
    "   OR LOWER(to_address) LIKE '%jeffrey epstein%'\n",
    "   OR LOWER(to_address) LIKE '%jeevacation%'\n",
    "   OR LOWER(to_address) LIKE '%jeeyacation%'\n",
    "   OR LOWER(to_address) LIKE '%jeffreyepstein%'\n",
    "   OR (to_address = 'J' AND message_order > 0)\n",
    "'''\n",
    "cursor.execute(update_to_query)\n",
    "\n",
    "conn.commit()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fix variants in from and to addresses\n",
    "Analysed common same from/to's using different name formats, initials, or email variants. -> standardize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Let's also change all variants to the standardized name:\n",
    "| Standardized Name     | Variants Detected                                 |\n",
    "| --------------------- | ------------------------------------------------- |\n",
    "| **Lawrence Summers**  | Larry Summers; Lawrence Summers; LHS              |\n",
    "| **Robert Kuhn**       | Robert Kuhn; Robert Lawrence Kuhn; Robert L. Kuhn |\n",
    "| **Nicholas Ribis**    | Nicholas Ribis; Nicholas Ribi                     |\n",
    "| **Boris Nikolic**     | Boris Nikolic; Boris Nikolic (bgC3)               |\n",
    "| **Martin Weinberg**   | Martin Weinberg; Martin G. Weinberg               |\n",
    "| **Ken Starr**         | Ken Starr; Starr, Ken                             |\n",
    "| **Ehud Barak**        | Ehud Barak; ehud barak                            |\n",
    "| **Landon Thomas Jr.** | Thomas Jr., Landon; Landon Thomas Jr.             |\n",
    "'''\n",
    "conn = sqlite3.connect(DB_PATH)\n",
    "standardizations = {\n",
    "    'Larry Summers': 'Lawrence Summers',\n",
    "    'Lawrence Summers': 'Lawrence Summers',\n",
    "    'LHS': 'Lawrence Summers',\n",
    "    'Robert Kuhn': 'Robert Kuhn',\n",
    "    'Robert Lawrence Kuhn': 'Robert Kuhn',\n",
    "    'Robert L. Kuhn': 'Robert Kuhn',\n",
    "    'Nicholas Ribis': 'Nicholas Ribis',\n",
    "    'Nicholas Ribi': 'Nicholas Ribis',\n",
    "    'Boris Nikolic': 'Boris Nikolic',\n",
    "    'Boris Nikolic (bgC3)': 'Boris Nikolic',\n",
    "    'Martin Weinberg': 'Martin Weinberg',\n",
    "    'Martin G. Weinberg': 'Martin Weinberg',\n",
    "    'Ken Starr': 'Ken Starr',\n",
    "    'Starr, Ken': 'Ken Starr',\n",
    "    'Ehud Barak': 'Ehud Barak',\n",
    "    'ehud barak': 'Ehud Barak',\n",
    "    'Thomas Jr., Landon': 'Landon Thomas Jr.',\n",
    "    'Landon Thomas Jr.': 'Landon Thomas Jr.'\n",
    "}\n",
    "\n",
    "for variant, standard in standardizations.items():\n",
    "    update_query = '''\n",
    "    UPDATE messages\n",
    "    SET from_address = ?\n",
    "    WHERE from_address = ?\n",
    "    '''\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(update_query, (standard, variant))\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Let's also change all variants to the standardized name:\n",
    "| Standardized Name     | Variants Detected                                                                         |\n",
    "| --------------------- | ----------------------------------------------------------------------------------------- |\n",
    "| **Lawrence Summers**  | Larry Summers, Lawrence H. Summers, Summers, Lawrence H., Lawrence Summers; LHS           |\n",
    "| **Robert Kuhn**       | Robert Kuhn, Robert Lawrence Kuhn                                                         |\n",
    "| **Martin Weinberg**   | Martin Weinberg, Martin G. Weinberg, 'Martin G. Weinberg'                                 |\n",
    "| **Ken Starr**         | Ken Starr, Starr, Ken                                                                     |\n",
    "| **Landon Thomas Jr.** | Thomas Jr., Landon, Landon Thomas Jr., Landon Thomas                                      |\n",
    "| **Ehud Barak**        | ehud barak, ehbarak                                                                       |\n",
    "| **Anas Alrasheed**    | Anas Alrasheed, anasalrasheed                                                             |\n",
    "| **Lisa New**          | Lisa New, Elisa New                                                                       |\n",
    "| **Steve Bannon**      | Steve Bannon, Steve Bannon                                                                |\n",
    "| **Boris Nikolic**     | Boris Nikolic, Boris Nikolic (bgC3)                                                       |\n",
    "\n",
    "'''\n",
    "conn = sqlite3.connect(DB_PATH)\n",
    "standardizations = {\n",
    "    'Larry Summers': 'Lawrence Summers',\n",
    "    'Lawrence H. Summers': 'Lawrence Summers',\n",
    "    'LHS': 'Lawrence Summers',\n",
    "    'Summers': 'Lawrence Summers',\n",
    "    'Lawrence H.': 'Lawrence Summers',\n",
    "    'Robert Kuhn': 'Robert Kuhn',\n",
    "    'Robert Lawrence Kuhn': 'Robert Kuhn',\n",
    "    'Martin Weinberg': 'Martin Weinberg',\n",
    "    'Martin G. Weinberg': 'Martin Weinberg',\n",
    "    'Martin G. Weinberg': 'Martin Weinberg',\n",
    "    'Ken Starr': 'Ken Starr',\n",
    "    'Starr': 'Ken Starr',\n",
    "    'Ken': 'Ken Starr',\n",
    "    'Thomas Jr., Landon': 'Landon Thomas Jr.',\n",
    "    'Landon': 'Landon Thomas Jr.',\n",
    "    'Landon Thomas Jr.': 'Landon Thomas Jr.',\n",
    "    'ehud barak': 'Ehud Barak',\n",
    "    'ehbarak': 'Ehud Barak',\n",
    "    'Anas Alrasheed': 'Anas Alrasheed',\n",
    "    'anasalrasheed': 'Anas Alrasheed',\n",
    "    'Lisa New': 'Lisa New',\n",
    "    'Elisa New': 'Lisa New',\n",
    "    'Steve Bannon': 'Steve Bannon',\n",
    "    'Boris Nikolic': 'Boris Nikolic',\n",
    "    'Boris Nikolic (bgC3)': 'Boris Nikolic'\n",
    "}\n",
    "\n",
    "for variant, standard in standardizations.items():\n",
    "    update_query = '''\n",
    "    UPDATE messages\n",
    "    SET to_address = ?\n",
    "    WHERE to_address = ?\n",
    "    '''\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(update_query, (standard, variant))\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fix REDACTED in from or to addresses\n",
    "\n",
    "we have a lot of redacted from or to\n",
    "what is going on here?\n",
    "eg: 019343, the prompt is bad, it chooses <REDACTED> over the name that *is* there, bummer -> rerun with VLM?\n",
    "i changed the prompt, right now we have 2517 lines that contain redacted :(\n",
    "changed prompt: now 2073 lines with redacted, but also 5 txt files failed because of parsing error\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find messages where from_address is <REDACTED> and where message_order = 0 or not\n",
    "conn = sqlite3.connect(DB_PATH)\n",
    "query = '''\n",
    "SELECT *\n",
    "FROM messages\n",
    "WHERE from_address = '<REDACTED>' AND message_order != 0\n",
    "'''\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(query)\n",
    "results = cursor.fetchall()\n",
    "for row in results:\n",
    "    print(row)\n",
    "conn.close()\n",
    "print(len(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "most redacted messages are where to_address = '<REDACTED>' AND message_order != 0\n",
    "i checked a few samples form the others cominations and they seem actually redacted\n",
    "although: 022668 it seems clear, don't know why. Maybe with Qwen3 VL?\n",
    "\n",
    "Let's make a new function that for each message where either from_address or to_address contains REDACTED (but noth both at the same time), we send it to an LLM to try again\n",
    "\n",
    "Question: is sometimes the from AND to_address <REDACTED>? -> YES: 46 cases :( but these will also be tried again\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resolve Redacted Addresses Function with enhanced capability for both-REDACTED messages\n",
    "def resolve_redacted_addresses():\n",
    "    \"\"\"\n",
    "    Function to resolve redacted from_address or to_address using LLM vision capabilities.\n",
    "    Processes messages where:\n",
    "    1. Either from_address OR to_address contains REDACTED (but not both)\n",
    "    2. Both from_address AND to_address contain REDACTED (allows partial resolution)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Original prompt template for single redacted addresses\n",
    "    SINGLE_REDACTED_PROMPT = \"\"\"From this document (which is an email thread) with the given image and OCR text, I have extracted this message.\n",
    "\n",
    "The {redacted_field} is unknown. Can you point it to a name or email address?\n",
    "\n",
    "Message details:\n",
    "- Subject: {subject}\n",
    "- Timestamp: {timestamp}\n",
    "- Current {known_field}: {known_value}\n",
    "- Message content: {message_content}\n",
    "\n",
    "Make sure to look at the timestamp and message content to find the right message in the thread!\n",
    "\n",
    "IMPORTANT!\n",
    "Only reply with the name or email address. Do not include any explanation or additional text.\n",
    "\n",
    "Document OCR Text:\n",
    "{ocr_text}\n",
    "Document images:\n",
    "\"\"\"\n",
    "\n",
    "    # New prompt template for both redacted addresses\n",
    "    BOTH_REDACTED_PROMPT = \"\"\"From this document (which is an email thread) with the given image and OCR text, I have extracted this message.\n",
    "\n",
    "Both the sender and recipient addresses are unknown. Can you identify both the FROM address and TO address?\n",
    "\n",
    "Message details:\n",
    "- Subject: {subject}\n",
    "- Timestamp: {timestamp}\n",
    "- Message content: {message_content}\n",
    "\n",
    "Make sure to look at the timestamp and message content to find the right message in the thread!\n",
    "\n",
    "IMPORTANT!\n",
    "Reply with EXACTLY this format:\n",
    "FROM: [sender name or email]\n",
    "TO: [recipient name or email]\n",
    "\n",
    "If you can only identify one of them, still use the format but put [redacted] for the unknown one.\n",
    "Do not include any explanation or additional text. Only use the format above.\n",
    "\n",
    "Document OCR Text:\n",
    "{ocr_text}\n",
    "Document images:\n",
    "\"\"\"\n",
    "\n",
    "    print(\"Starting redacted address resolution...\")\n",
    "    \n",
    "    # Connect to database and get messages with redacted addresses\n",
    "    conn = sqlite3.connect(DB_PATH)\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # Query for messages with single redacted address (either from OR to, but not both)\n",
    "    single_redacted_query = '''\n",
    "    SELECT id, source_filename, subject, from_address, to_address, timestamp_raw, message_html, document_id, 'single' as redaction_type\n",
    "    FROM messages \n",
    "    WHERE (\n",
    "        (from_address LIKE '%REDACTED%' AND to_address NOT LIKE '%REDACTED%') \n",
    "        OR \n",
    "        (to_address LIKE '%REDACTED%' AND from_address NOT LIKE '%REDACTED%')\n",
    "    )\n",
    "    '''\n",
    "    \n",
    "    # Query for messages with both addresses redacted\n",
    "    both_redacted_query = '''\n",
    "    SELECT id, source_filename, subject, from_address, to_address, timestamp_raw, message_html, document_id, 'both' as redaction_type\n",
    "    FROM messages \n",
    "    WHERE from_address LIKE '%REDACTED%' AND to_address LIKE '%REDACTED%'\n",
    "    '''\n",
    "    \n",
    "    # Combine both queries\n",
    "    combined_query = f'''\n",
    "    {single_redacted_query}\n",
    "    UNION ALL\n",
    "    {both_redacted_query}\n",
    "    ORDER BY source_filename\n",
    "    '''\n",
    "    \n",
    "    cursor.execute(combined_query)\n",
    "    redacted_messages = cursor.fetchall()\n",
    "    \n",
    "    print(f\"Found {len(redacted_messages)} messages with redacted addresses\")\n",
    "    \n",
    "    # Count different types\n",
    "    single_redacted_count = len([msg for msg in redacted_messages if msg[8] == 'single'])\n",
    "    both_redacted_count = len([msg for msg in redacted_messages if msg[8] == 'both'])\n",
    "    \n",
    "    print(f\"  - Single redacted: {single_redacted_count}\")\n",
    "    print(f\"  - Both redacted: {both_redacted_count}\")\n",
    "    \n",
    "    if len(redacted_messages) == 0:\n",
    "        print(\"No messages found with redacted addresses.\")\n",
    "        conn.close()\n",
    "        return []\n",
    "    \n",
    "    replacements = []\n",
    "    processed_count = 0\n",
    "    \n",
    "    def is_valid_address(address):\n",
    "        \"\"\"Check if an address is valid (not redacted, unknown, etc.)\"\"\"\n",
    "        if not address or len(address) < 2:\n",
    "            return False\n",
    "        skip_responses = ['unknown', 'redacted', 'not found', 'unclear', 'cannot determine', 'n/a', '[redacted]']\n",
    "        return not any(skip_word in address.lower() for skip_word in skip_responses)\n",
    "    \n",
    "    for message in tqdm(redacted_messages, desc=\"Resolving redacted addresses\"):\n",
    "        msg_id, source_filename, subject, from_addr, to_addr, timestamp_raw, message_html, document_id, redaction_type = message\n",
    "        \n",
    "        try:\n",
    "            # Get the OCR text file\n",
    "            text_path = get_text_file_path(source_filename)\n",
    "            if not text_path:\n",
    "                print(f\"Warning: Could not find text file for {source_filename}\")\n",
    "                continue\n",
    "                \n",
    "            with open(text_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "                ocr_text = f.read()\n",
    "            \n",
    "            # Get the document image\n",
    "            if document_id:\n",
    "                # Try to find image in data/sources first (already processed)\n",
    "                source_image_path = Path('data/sources') / f\"{Path(source_filename).stem}.jpg\"\n",
    "                if source_image_path.exists():\n",
    "                    image_base64 = resize_and_encode_image(source_image_path)\n",
    "                else:\n",
    "                    # Fall back to searching in DATASET_ROOT/IMAGES\n",
    "                    images_dir = DATASET_ROOT / 'IMAGES'\n",
    "                    pattern = f\"**/{Path(source_filename).stem}.jpg\"\n",
    "                    matching_files = list(images_dir.glob(pattern))\n",
    "                    if matching_files:\n",
    "                        image_base64 = resize_and_encode_image(matching_files[0])\n",
    "                    else:\n",
    "                        print(f\"Warning: Could not find image for document {source_filename}\")\n",
    "                        continue\n",
    "            else:\n",
    "                print(f\"Warning: No document_id for message {msg_id}\")\n",
    "                continue\n",
    "            \n",
    "            if not image_base64:\n",
    "                print(f\"Warning: Could not encode image for document {document_id}\")\n",
    "                continue\n",
    "            \n",
    "            # Clean message HTML for display\n",
    "            clean_message = clean_html_for_comparison(message_html)\n",
    "            \n",
    "            # Handle based on redaction type\n",
    "            if redaction_type == 'single':\n",
    "                # Single redacted address - use original logic\n",
    "                if 'REDACTED' in from_addr:\n",
    "                    redacted_field = \"from_address\"\n",
    "                    known_field = \"to_address\" \n",
    "                    known_value = to_addr\n",
    "                    redacted_value = from_addr\n",
    "                else:\n",
    "                    redacted_field = \"to_address\"\n",
    "                    known_field = \"from_address\"\n",
    "                    known_value = from_addr\n",
    "                    redacted_value = to_addr\n",
    "                \n",
    "                # Format the single redacted prompt\n",
    "                prompt = SINGLE_REDACTED_PROMPT.format(\n",
    "                    redacted_field=redacted_field.replace('_', ' '),\n",
    "                    subject=subject,\n",
    "                    timestamp=timestamp_raw,\n",
    "                    known_field=known_field.replace('_', ' '),\n",
    "                    known_value=known_value,\n",
    "                    message_content=clean_message,\n",
    "                    ocr_text=ocr_text\n",
    "                )\n",
    "                \n",
    "            else:\n",
    "                # Both addresses redacted - use new logic\n",
    "                prompt = BOTH_REDACTED_PROMPT.format(\n",
    "                    subject=subject,\n",
    "                    timestamp=timestamp_raw,\n",
    "                    message_content=clean_message,\n",
    "                    ocr_text=ocr_text\n",
    "                )\n",
    "            \n",
    "            # Call the LLM\n",
    "            content = [\n",
    "                {\"type\": \"text\", \"text\": prompt},\n",
    "                {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image_base64}\"}}\n",
    "            ]\n",
    "            \n",
    "            response = client.chat.completions.create(\n",
    "                model=OPENAI_API_MODEL,\n",
    "                messages=[{\"role\": \"user\", \"content\": content}],\n",
    "                temperature=0,\n",
    "                max_tokens=150  # Slightly more tokens for both-redacted responses\n",
    "            )\n",
    "            \n",
    "            # Process the response based on redaction type\n",
    "            response_text = response.choices[0].message.content.strip()\n",
    "            \n",
    "            if redaction_type == 'single':\n",
    "                # Single redacted - process as before\n",
    "                resolved_address = response_text.strip('\"\\'')\n",
    "                \n",
    "                if not is_valid_address(resolved_address):\n",
    "                    print(f\"Skipping message {msg_id}: Invalid response - {resolved_address}\")\n",
    "                    continue\n",
    "                \n",
    "                # Update the database\n",
    "                if redacted_field == \"from_address\":\n",
    "                    cursor.execute(\"UPDATE messages SET from_address = ? WHERE id = ?\", (resolved_address, msg_id))\n",
    "                else:\n",
    "                    cursor.execute(\"UPDATE messages SET to_address = ? WHERE id = ?\", (resolved_address, msg_id))\n",
    "                \n",
    "                # Track the replacement\n",
    "                replacements.append({\n",
    "                    'message_id': msg_id,\n",
    "                    'source_filename': source_filename,\n",
    "                    'field': redacted_field,\n",
    "                    'original': redacted_value,\n",
    "                    'resolved': resolved_address,\n",
    "                    'timestamp': timestamp_raw,\n",
    "                    'subject': subject[:50] + \"...\" if len(subject) > 50 else subject\n",
    "                })\n",
    "                \n",
    "            else:\n",
    "                # Both redacted - parse the structured response and allow partial updates\n",
    "                lines = response_text.split('\\n')\n",
    "                from_resolved = None\n",
    "                to_resolved = None\n",
    "                \n",
    "                for line in lines:\n",
    "                    line = line.strip()\n",
    "                    if line.upper().startswith('FROM:'):\n",
    "                        from_resolved = line[5:].strip().strip('\"\\'')\n",
    "                    elif line.upper().startswith('TO:'):\n",
    "                        to_resolved = line[3:].strip().strip('\"\\'')\n",
    "                \n",
    "                # Check which addresses are valid\n",
    "                valid_from = is_valid_address(from_resolved)\n",
    "                valid_to = is_valid_address(to_resolved)\n",
    "                \n",
    "                # Skip only if neither address could be resolved\n",
    "                if not valid_from and not valid_to:\n",
    "                    print(f\"Skipping message {msg_id}: Could not resolve any addresses - FROM: '{from_resolved}', TO: '{to_resolved}'\")\n",
    "                    continue\n",
    "                \n",
    "                # Update whatever we can resolve\n",
    "                updates_made = []\n",
    "                \n",
    "                if valid_from:\n",
    "                    cursor.execute(\"UPDATE messages SET from_address = ? WHERE id = ?\", (from_resolved, msg_id))\n",
    "                    replacements.append({\n",
    "                        'message_id': msg_id,\n",
    "                        'source_filename': source_filename,\n",
    "                        'field': 'from_address',\n",
    "                        'original': from_addr,\n",
    "                        'resolved': from_resolved,\n",
    "                        'timestamp': timestamp_raw,\n",
    "                        'subject': subject[:50] + \"...\" if len(subject) > 50 else subject\n",
    "                    })\n",
    "                    updates_made.append(f\"FROM: {from_resolved}\")\n",
    "                \n",
    "                if valid_to:\n",
    "                    cursor.execute(\"UPDATE messages SET to_address = ? WHERE id = ?\", (to_resolved, msg_id))\n",
    "                    replacements.append({\n",
    "                        'message_id': msg_id,\n",
    "                        'source_filename': source_filename,\n",
    "                        'field': 'to_address',\n",
    "                        'original': to_addr,\n",
    "                        'resolved': to_resolved,\n",
    "                        'timestamp': timestamp_raw,\n",
    "                        'subject': subject[:50] + \"...\" if len(subject) > 50 else subject\n",
    "                    })\n",
    "                    updates_made.append(f\"TO: {to_resolved}\")\n",
    "                \n",
    "                # Log what was updated\n",
    "                if len(updates_made) == 1:\n",
    "                    print(f\"Partial resolution for message {msg_id}: {updates_made[0]} (other field remains REDACTED)\")\n",
    "            \n",
    "            processed_count += 1\n",
    "            \n",
    "            # Print progress every 100 successful resolutions\n",
    "            if processed_count % 100 == 0:\n",
    "                print(f\"Successfully processed {processed_count} messages...\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing message {msg_id}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    # Commit all changes\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"REDACTED ADDRESS RESOLUTION COMPLETE\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Total messages processed: {len(redacted_messages)}\")\n",
    "    print(f\"  - Single redacted: {single_redacted_count}\")\n",
    "    print(f\"  - Both redacted: {both_redacted_count}\")\n",
    "    print(f\"Successfully processed: {processed_count}\")\n",
    "    print(f\"Success rate: {(processed_count/len(redacted_messages)*100):.1f}%\")\n",
    "    \n",
    "    if replacements:\n",
    "        print(f\"\\nREPLACEMENT SUMMARY:\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        # Group by field type\n",
    "        from_replacements = [r for r in replacements if r['field'] == 'from_address']\n",
    "        to_replacements = [r for r in replacements if r['field'] == 'to_address']\n",
    "        \n",
    "        print(f\"From address resolutions: {len(from_replacements)}\")\n",
    "        print(f\"To address resolutions: {len(to_replacements)}\")\n",
    "        \n",
    "        print(f\"\\nDETAILED REPLACEMENTS:\")\n",
    "        print(f\"{'ID':<8} {'Field':<12} {'Original':<15} {'Resolved':<25} {'Source':<15}\")\n",
    "        print(f\"{'-'*80}\")\n",
    "        \n",
    "        for replacement in replacements[:50]:  # Show first 50\n",
    "            print(f\"{replacement['message_id']:<8} {replacement['field']:<12} {replacement['original']:<15} {replacement['resolved']:<25} {replacement['source_filename'][:12]:<15}\")\n",
    "        \n",
    "        if len(replacements) > 50:\n",
    "            print(f\"... and {len(replacements) - 50} more replacements\")\n",
    "        \n",
    "        # Show most common resolved addresses\n",
    "        resolved_addresses = [r['resolved'] for r in replacements]\n",
    "        from collections import Counter\n",
    "        most_common = Counter(resolved_addresses).most_common(30)\n",
    "        \n",
    "        print(f\"\\nMOST COMMON RESOLVED ADDRESSES:\")\n",
    "        print(f\"{'='*40}\")\n",
    "        for address, count in most_common:\n",
    "            print(f\"{address}: {count} times\")\n",
    "    \n",
    "    return replacements\n",
    "\n",
    "# Execute the function\n",
    "print(\"Ready to execute resolve_redacted_addresses() with partial resolution support\")\n",
    "replacements = resolve_redacted_addresses()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "weird: HOUSE_OVERSIGHT_022770 is a tif file, not jpg. Todo: are there more other formats?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem: 79 messages have HOUSE_OVERSIGHT_XXXXXX as their document_id, which means they will not have a link to their image...\n",
    "we could do another step here to send those again to a LLM\n",
    "or default them to the first page of the thread"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fix timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated 12 messages with corrected timestamps\n"
     ]
    }
   ],
   "source": [
    "# i see about 10 out of 7000 messages that don't have a timestamp_iso or they are '00000000000000', they are however always message_order > 0\n",
    "# let's just take the timestamp_iso of the first message in the thread (message_order = 0) for that source_filename and use that\n",
    "# time minus 30 seconds\n",
    "conn = sqlite3.connect(DB_PATH)\n",
    "query = '''\n",
    "UPDATE messages AS m1\n",
    "SET timestamp_iso = (\n",
    "    SELECT \n",
    "        strftime('%Y%m%d%H%M%S', \n",
    "            datetime(\n",
    "                substr(m2.timestamp_iso, 1, 4) || '-' ||\n",
    "                substr(m2.timestamp_iso, 5, 2) || '-' ||\n",
    "                substr(m2.timestamp_iso, 7, 2) || ' ' ||\n",
    "                substr(m2.timestamp_iso, 9, 2) || ':' ||\n",
    "                substr(m2.timestamp_iso, 11, 2) || ':' ||\n",
    "                substr(m2.timestamp_iso, 13, 2),\n",
    "                '-30 seconds'\n",
    "            )\n",
    "        )\n",
    "    FROM messages AS m2\n",
    "    WHERE m2.source_filename = m1.source_filename \n",
    "      AND m2.message_order = 0\n",
    "      AND m2.timestamp_iso IS NOT NULL\n",
    "      AND m2.timestamp_iso != ''\n",
    "    LIMIT 1\n",
    ")\n",
    "WHERE m1.timestamp_iso IS NULL OR m1.timestamp_iso = '' OR m1.timestamp_iso = '00000000000000'\n",
    "'''\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(query)\n",
    "rows_updated = cursor.rowcount\n",
    "conn.commit()\n",
    "conn.close()\n",
    "print(f\"Updated {rows_updated} messages with corrected timestamps\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total duplicate messages found: 385\n"
     ]
    }
   ],
   "source": [
    "# count duplicate messages: improved version with HTML cleaning and adaptive thresholds\n",
    "import difflib\n",
    "from datetime import datetime\n",
    "conn = sqlite3.connect(DB_PATH)\n",
    "cursor = conn.cursor()\n",
    "query = '''\n",
    "SELECT m1.id, m1.source_filename, m1.from_address, m1.to_address, m1.timestamp_iso, m1.message_html,\n",
    "       m2.id, m2.source_filename, m2.from_address, m2.to_address, m2.timestamp_iso, m2.message_html\n",
    "FROM messages m1\n",
    "JOIN messages m2 ON m1.from_address = m2.from_address AND m1.to_address = m2.to_address AND m1.id < m2.id\n",
    "'''\n",
    "cursor.execute(query)\n",
    "rows = cursor.fetchall()\n",
    "duplicate_count = 0\n",
    "for row in rows:\n",
    "    msg1_html = row[5]\n",
    "    msg2_html = row[11]\n",
    "    time1_str = row[4]\n",
    "    time2_str = row[10]\n",
    "    \n",
    "    # Parse timestamps properly\n",
    "    try:\n",
    "        time1 = datetime.strptime(time1_str, '%Y%m%d%H%M%S')\n",
    "        time2 = datetime.strptime(time2_str, '%Y%m%d%H%M%S')\n",
    "    except:\n",
    "        print(f\"Invalid timestamp format for message IDs {row[0]} and {row[6]}: '{time1_str}' or '{time2_str}'\")\n",
    "        continue  # Skip if timestamp format is invalid\n",
    "    \n",
    "    # Calculate time difference in minutes\n",
    "    time_diff_minutes = abs((time2 - time1).total_seconds()) / 60\n",
    "    \n",
    "    if time_diff_minutes <= 5:\n",
    "        # Clean HTML tags and normalize whitespace before comparison\n",
    "        cleaned_msg1 = clean_html_for_comparison(msg1_html)\n",
    "        cleaned_msg2 = clean_html_for_comparison(msg2_html)\n",
    "        \n",
    "        # Determine adaptive threshold based on message length\n",
    "        cleaned_len = len(cleaned_msg1)\n",
    "        if cleaned_len < 100:\n",
    "            threshold = 0.90  # More lenient for short messages\n",
    "        elif cleaned_len < 500:\n",
    "            threshold = 0.95\n",
    "        else:\n",
    "            threshold = 0.98  # Stricter for longer messages\n",
    "        \n",
    "        # Check similarity on cleaned text\n",
    "        similarity = difflib.SequenceMatcher(None, cleaned_msg1, cleaned_msg2).ratio()\n",
    "        if similarity >= threshold:\n",
    "            duplicate_count += 1\n",
    "            # print(f\"Duplicate found between message ID {row[0]} ({row[1]}) and message ID {row[6]} ({row[7]}) with similarity {similarity:.2f} (threshold: {threshold})\")\n",
    "\n",
    "print(f\"Total duplicate messages found: {duplicate_count}\")\n",
    "conn.close()    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remove duplicate messages\n",
    "\n",
    "there seem to be a lot of duplicate messages 2465 out of 6822\n",
    "eg 12898 & 33575 -> same doc but different (redactions are different)\n",
    "eg 019334 & 019348 -> replies at different times in a thread, causing forks -> messages are the same\n",
    "This leads me to believe we can delete all duplicate messages\n",
    "But which ones? The ones with the highest message order? But what if they have the same message order?\n",
    "Maybe it doesn't matter.\n",
    "\"LMAO<br>Perfect mnuchin hit\" and \"<p>LMAO</p><p>Perfect mnuchin hit</p>\" are not considered the same -> lets delete all html before comparing\n",
    "1162 duplicates before, now : 921 -> This is actually more accurate! We're now finding true duplicates rather than messages that just had similar HTML structure. If we extend the time from 5mins to 24h, it jumps to 1641"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marking message ID 143 for deletion (duplicate of ID 58) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 108 for deletion (duplicate of ID 59) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 105 for deletion (duplicate of ID 72) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 141 for deletion (duplicate of ID 88) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 201 for deletion (duplicate of ID 145) with similarity 0.95 (threshold: 0.9)\n",
      "Marking message ID 359 for deletion (duplicate of ID 163) with similarity 1.00 (threshold: 0.98)\n",
      "Marking message ID 3450 for deletion (duplicate of ID 176) with similarity 0.97 (threshold: 0.95)\n",
      "Marking message ID 4471 for deletion (duplicate of ID 176) with similarity 0.97 (threshold: 0.95)\n",
      "Marking message ID 4468 for deletion (duplicate of ID 176) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 216 for deletion (duplicate of ID 179) with similarity 1.00 (threshold: 0.98)\n",
      "Marking message ID 275 for deletion (duplicate of ID 255) with similarity 0.99 (threshold: 0.9)\n",
      "Marking message ID 279 for deletion (duplicate of ID 255) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 293 for deletion (duplicate of ID 272) with similarity 1.00 (threshold: 0.98)\n",
      "Marking message ID 279 for deletion (duplicate of ID 275) with similarity 0.99 (threshold: 0.9)\n",
      "Marking message ID 315 for deletion (duplicate of ID 277) with similarity 1.00 (threshold: 0.98)\n",
      "Marking message ID 383 for deletion (duplicate of ID 277) with similarity 1.00 (threshold: 0.98)\n",
      "Marking message ID 310 for deletion (duplicate of ID 285) with similarity 1.00 (threshold: 0.98)\n",
      "Marking message ID 293 for deletion (duplicate of ID 289) with similarity 0.99 (threshold: 0.98)\n",
      "Marking message ID 361 for deletion (duplicate of ID 309) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 385 for deletion (duplicate of ID 313) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 383 for deletion (duplicate of ID 315) with similarity 1.00 (threshold: 0.98)\n",
      "Marking message ID 412 for deletion (duplicate of ID 321) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 452 for deletion (duplicate of ID 331) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 428 for deletion (duplicate of ID 332) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 453 for deletion (duplicate of ID 332) with similarity 0.99 (threshold: 0.95)\n",
      "Marking message ID 363 for deletion (duplicate of ID 336) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 357 for deletion (duplicate of ID 337) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 443 for deletion (duplicate of ID 343) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 365 for deletion (duplicate of ID 354) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 364 for deletion (duplicate of ID 355) with similarity 1.00 (threshold: 0.98)\n",
      "Marking message ID 484 for deletion (duplicate of ID 400) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 420 for deletion (duplicate of ID 403) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 441 for deletion (duplicate of ID 404) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 436 for deletion (duplicate of ID 425) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 481 for deletion (duplicate of ID 425) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 453 for deletion (duplicate of ID 428) with similarity 0.99 (threshold: 0.95)\n",
      "Marking message ID 481 for deletion (duplicate of ID 436) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 485 for deletion (duplicate of ID 444) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 2841 for deletion (duplicate of ID 456) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 480 for deletion (duplicate of ID 475) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 2827 for deletion (duplicate of ID 482) with similarity 0.99 (threshold: 0.98)\n",
      "Marking message ID 511 for deletion (duplicate of ID 494) with similarity 1.00 (threshold: 0.98)\n",
      "Marking message ID 506 for deletion (duplicate of ID 494) with similarity 1.00 (threshold: 0.98)\n",
      "Marking message ID 515 for deletion (duplicate of ID 501) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 511 for deletion (duplicate of ID 506) with similarity 1.00 (threshold: 0.98)\n",
      "Marking message ID 510 for deletion (duplicate of ID 508) with similarity 1.00 (threshold: 0.98)\n",
      "Marking message ID 2191 for deletion (duplicate of ID 508) with similarity 1.00 (threshold: 0.98)\n",
      "Marking message ID 2191 for deletion (duplicate of ID 510) with similarity 1.00 (threshold: 0.98)\n",
      "Marking message ID 518 for deletion (duplicate of ID 517) with similarity 0.99 (threshold: 0.98)\n",
      "Marking message ID 530 for deletion (duplicate of ID 520) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 547 for deletion (duplicate of ID 526) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 582 for deletion (duplicate of ID 533) with similarity 1.00 (threshold: 0.98)\n",
      "Marking message ID 536 for deletion (duplicate of ID 534) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 580 for deletion (duplicate of ID 535) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 584 for deletion (duplicate of ID 537) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 1987 for deletion (duplicate of ID 545) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 2215 for deletion (duplicate of ID 545) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 2247 for deletion (duplicate of ID 545) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 679 for deletion (duplicate of ID 559) with similarity 0.99 (threshold: 0.98)\n",
      "Marking message ID 648 for deletion (duplicate of ID 608) with similarity 0.99 (threshold: 0.95)\n",
      "Marking message ID 650 for deletion (duplicate of ID 610) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 660 for deletion (duplicate of ID 612) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 725 for deletion (duplicate of ID 642) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 668 for deletion (duplicate of ID 642) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 670 for deletion (duplicate of ID 644) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 725 for deletion (duplicate of ID 668) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 4820 for deletion (duplicate of ID 673) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 3689 for deletion (duplicate of ID 689) with similarity 1.00 (threshold: 0.98)\n",
      "Marking message ID 727 for deletion (duplicate of ID 690) with similarity 1.00 (threshold: 0.98)\n",
      "Marking message ID 762 for deletion (duplicate of ID 700) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 764 for deletion (duplicate of ID 702) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 760 for deletion (duplicate of ID 710) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 1320 for deletion (duplicate of ID 716) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 746 for deletion (duplicate of ID 738) with similarity 0.99 (threshold: 0.95)\n",
      "Marking message ID 771 for deletion (duplicate of ID 749) with similarity 0.96 (threshold: 0.9)\n",
      "Marking message ID 779 for deletion (duplicate of ID 749) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 1876 for deletion (duplicate of ID 749) with similarity 0.96 (threshold: 0.9)\n",
      "Marking message ID 781 for deletion (duplicate of ID 751) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 1881 for deletion (duplicate of ID 751) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 1877 for deletion (duplicate of ID 752) with similarity 1.00 (threshold: 0.98)\n",
      "Marking message ID 776 for deletion (duplicate of ID 754) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 783 for deletion (duplicate of ID 754) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 779 for deletion (duplicate of ID 771) with similarity 0.96 (threshold: 0.95)\n",
      "Marking message ID 1876 for deletion (duplicate of ID 771) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 783 for deletion (duplicate of ID 776) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 1876 for deletion (duplicate of ID 779) with similarity 0.96 (threshold: 0.9)\n",
      "Marking message ID 1881 for deletion (duplicate of ID 781) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 1368 for deletion (duplicate of ID 806) with similarity 0.99 (threshold: 0.95)\n",
      "Marking message ID 1904 for deletion (duplicate of ID 812) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 4280 for deletion (duplicate of ID 812) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 1902 for deletion (duplicate of ID 814) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 1945 for deletion (duplicate of ID 814) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 1947 for deletion (duplicate of ID 816) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 926 for deletion (duplicate of ID 822) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 1392 for deletion (duplicate of ID 827) with similarity 1.00 (threshold: 0.98)\n",
      "Marking message ID 928 for deletion (duplicate of ID 830) with similarity 0.99 (threshold: 0.95)\n",
      "Marking message ID 918 for deletion (duplicate of ID 841) with similarity 0.99 (threshold: 0.95)\n",
      "Marking message ID 2847 for deletion (duplicate of ID 841) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 2897 for deletion (duplicate of ID 841) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 916 for deletion (duplicate of ID 843) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 2867 for deletion (duplicate of ID 843) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 2899 for deletion (duplicate of ID 843) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 914 for deletion (duplicate of ID 845) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 2901 for deletion (duplicate of ID 845) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 912 for deletion (duplicate of ID 847) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 900 for deletion (duplicate of ID 847) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 4538 for deletion (duplicate of ID 854) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 1577 for deletion (duplicate of ID 866) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 1583 for deletion (duplicate of ID 872) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 1084 for deletion (duplicate of ID 875) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 1039 for deletion (duplicate of ID 877) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 4658 for deletion (duplicate of ID 886) with similarity 0.99 (threshold: 0.95)\n",
      "Marking message ID 4666 for deletion (duplicate of ID 888) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 912 for deletion (duplicate of ID 900) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 2901 for deletion (duplicate of ID 914) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 2867 for deletion (duplicate of ID 916) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 2899 for deletion (duplicate of ID 916) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 2847 for deletion (duplicate of ID 918) with similarity 0.99 (threshold: 0.95)\n",
      "Marking message ID 2897 for deletion (duplicate of ID 918) with similarity 0.99 (threshold: 0.95)\n",
      "Marking message ID 946 for deletion (duplicate of ID 934) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 940 for deletion (duplicate of ID 934) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 1098 for deletion (duplicate of ID 934) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 944 for deletion (duplicate of ID 936) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 938 for deletion (duplicate of ID 936) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 1425 for deletion (duplicate of ID 936) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 944 for deletion (duplicate of ID 938) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 1425 for deletion (duplicate of ID 938) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 946 for deletion (duplicate of ID 940) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 1098 for deletion (duplicate of ID 940) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 980 for deletion (duplicate of ID 942) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 1027 for deletion (duplicate of ID 942) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 1425 for deletion (duplicate of ID 944) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 1098 for deletion (duplicate of ID 946) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 1699 for deletion (duplicate of ID 974) with similarity 0.98 (threshold: 0.9)\n",
      "Marking message ID 1027 for deletion (duplicate of ID 980) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 1102 for deletion (duplicate of ID 982) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 1060 for deletion (duplicate of ID 982) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 4901 for deletion (duplicate of ID 986) with similarity 0.97 (threshold: 0.9)\n",
      "Marking message ID 5116 for deletion (duplicate of ID 986) with similarity 0.97 (threshold: 0.9)\n",
      "Marking message ID 1082 for deletion (duplicate of ID 990) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 1104 for deletion (duplicate of ID 1002) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 1025 for deletion (duplicate of ID 1002) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 1043 for deletion (duplicate of ID 1005) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 1104 for deletion (duplicate of ID 1025) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 1102 for deletion (duplicate of ID 1060) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 1155 for deletion (duplicate of ID 1088) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 1110 for deletion (duplicate of ID 1094) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 1144 for deletion (duplicate of ID 1111) with similarity 0.99 (threshold: 0.95)\n",
      "Marking message ID 1469 for deletion (duplicate of ID 1111) with similarity 0.99 (threshold: 0.95)\n",
      "Marking message ID 4893 for deletion (duplicate of ID 1125) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 5870 for deletion (duplicate of ID 1127) with similarity 0.98 (threshold: 0.98)\n",
      "Marking message ID 5872 for deletion (duplicate of ID 1129) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 1469 for deletion (duplicate of ID 1144) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 1207 for deletion (duplicate of ID 1149) with similarity 0.96 (threshold: 0.95)\n",
      "Marking message ID 1436 for deletion (duplicate of ID 1149) with similarity 0.96 (threshold: 0.95)\n",
      "Marking message ID 1170 for deletion (duplicate of ID 1165) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 1291 for deletion (duplicate of ID 1165) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 1291 for deletion (duplicate of ID 1170) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 1293 for deletion (duplicate of ID 1172) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 1329 for deletion (duplicate of ID 1172) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 1765 for deletion (duplicate of ID 1173) with similarity 0.99 (threshold: 0.98)\n",
      "Marking message ID 2933 for deletion (duplicate of ID 1174) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 1225 for deletion (duplicate of ID 1187) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 1436 for deletion (duplicate of ID 1207) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 1245 for deletion (duplicate of ID 1224) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 1277 for deletion (duplicate of ID 1238) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 1329 for deletion (duplicate of ID 1293) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 1331 for deletion (duplicate of ID 1295) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 1500 for deletion (duplicate of ID 1296) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 4655 for deletion (duplicate of ID 1383) with similarity 1.00 (threshold: 0.98)\n",
      "Marking message ID 1632 for deletion (duplicate of ID 1385) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 1432 for deletion (duplicate of ID 1399) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 1440 for deletion (duplicate of ID 1404) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 2905 for deletion (duplicate of ID 1428) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 5291 for deletion (duplicate of ID 1450) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 3734 for deletion (duplicate of ID 1476) with similarity 1.00 (threshold: 0.98)\n",
      "Marking message ID 2999 for deletion (duplicate of ID 1548) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 1698 for deletion (duplicate of ID 1558) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 1671 for deletion (duplicate of ID 1563) with similarity 0.95 (threshold: 0.9)\n",
      "Marking message ID 1673 for deletion (duplicate of ID 1565) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 1702 for deletion (duplicate of ID 1623) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 1716 for deletion (duplicate of ID 1623) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 1647 for deletion (duplicate of ID 1628) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 1700 for deletion (duplicate of ID 1664) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 1716 for deletion (duplicate of ID 1702) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 1819 for deletion (duplicate of ID 1715) with similarity 1.00 (threshold: 0.98)\n",
      "Marking message ID 3500 for deletion (duplicate of ID 1749) with similarity 0.99 (threshold: 0.9)\n",
      "Marking message ID 2106 for deletion (duplicate of ID 1811) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 2097 for deletion (duplicate of ID 1820) with similarity 0.98 (threshold: 0.9)\n",
      "Marking message ID 1870 for deletion (duplicate of ID 1826) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 2015 for deletion (duplicate of ID 1826) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 1931 for deletion (duplicate of ID 1827) with similarity 0.99 (threshold: 0.95)\n",
      "Marking message ID 1868 for deletion (duplicate of ID 1828) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 2017 for deletion (duplicate of ID 1828) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 1928 for deletion (duplicate of ID 1830) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 2004 for deletion (duplicate of ID 1832) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 2006 for deletion (duplicate of ID 1833) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 1939 for deletion (duplicate of ID 1834) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 2008 for deletion (duplicate of ID 1834) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 1937 for deletion (duplicate of ID 1835) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 2010 for deletion (duplicate of ID 1835) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 1873 for deletion (duplicate of ID 1836) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 2012 for deletion (duplicate of ID 1836) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 2117 for deletion (duplicate of ID 1839) with similarity 0.98 (threshold: 0.95)\n",
      "Marking message ID 2143 for deletion (duplicate of ID 1851) with similarity 1.00 (threshold: 0.98)\n",
      "Marking message ID 1927 for deletion (duplicate of ID 1852) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 1866 for deletion (duplicate of ID 1853) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 2019 for deletion (duplicate of ID 1853) with similarity 0.99 (threshold: 0.9)\n",
      "Marking message ID 1933 for deletion (duplicate of ID 1858) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 1872 for deletion (duplicate of ID 1859) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 2013 for deletion (duplicate of ID 1859) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 2426 for deletion (duplicate of ID 1864) with similarity 1.00 (threshold: 0.98)\n",
      "Marking message ID 2019 for deletion (duplicate of ID 1866) with similarity 0.99 (threshold: 0.9)\n",
      "Marking message ID 2017 for deletion (duplicate of ID 1868) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 2015 for deletion (duplicate of ID 1870) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 2013 for deletion (duplicate of ID 1872) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 2012 for deletion (duplicate of ID 1873) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 1936 for deletion (duplicate of ID 1874) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 1938 for deletion (duplicate of ID 1886) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 2413 for deletion (duplicate of ID 1899) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 3680 for deletion (duplicate of ID 1899) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 1945 for deletion (duplicate of ID 1902) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 4280 for deletion (duplicate of ID 1904) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 2165 for deletion (duplicate of ID 1911) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 2010 for deletion (duplicate of ID 1937) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 2008 for deletion (duplicate of ID 1939) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 3076 for deletion (duplicate of ID 1949) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 4385 for deletion (duplicate of ID 1949) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 2198 for deletion (duplicate of ID 1967) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 1998 for deletion (duplicate of ID 1972) with similarity 1.00 (threshold: 0.98)\n",
      "Marking message ID 4535 for deletion (duplicate of ID 1983) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 4532 for deletion (duplicate of ID 1985) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 2215 for deletion (duplicate of ID 1987) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 2247 for deletion (duplicate of ID 1987) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 2070 for deletion (duplicate of ID 1995) with similarity 1.00 (threshold: 0.98)\n",
      "Marking message ID 2268 for deletion (duplicate of ID 1995) with similarity 1.00 (threshold: 0.98)\n",
      "Marking message ID 2069 for deletion (duplicate of ID 1996) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 2068 for deletion (duplicate of ID 1997) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 2045 for deletion (duplicate of ID 2000) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 2046 for deletion (duplicate of ID 2001) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 2188 for deletion (duplicate of ID 2050) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 2268 for deletion (duplicate of ID 2070) with similarity 1.00 (threshold: 0.98)\n",
      "Marking message ID 2170 for deletion (duplicate of ID 2132) with similarity 0.99 (threshold: 0.9)\n",
      "Marking message ID 2172 for deletion (duplicate of ID 2134) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 2209 for deletion (duplicate of ID 2137) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 2247 for deletion (duplicate of ID 2215) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 6505 for deletion (duplicate of ID 2244) with similarity 1.00 (threshold: 0.98)\n",
      "Marking message ID 2304 for deletion (duplicate of ID 2300) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 2374 for deletion (duplicate of ID 2300) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 2374 for deletion (duplicate of ID 2304) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 2372 for deletion (duplicate of ID 2306) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 2320 for deletion (duplicate of ID 2309) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 2348 for deletion (duplicate of ID 2310) with similarity 1.00 (threshold: 0.98)\n",
      "Marking message ID 2381 for deletion (duplicate of ID 2317) with similarity 0.99 (threshold: 0.9)\n",
      "Marking message ID 2394 for deletion (duplicate of ID 2322) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 2393 for deletion (duplicate of ID 2323) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 2377 for deletion (duplicate of ID 2325) with similarity 1.00 (threshold: 0.98)\n",
      "Marking message ID 2379 for deletion (duplicate of ID 2327) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 2388 for deletion (duplicate of ID 2338) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 2390 for deletion (duplicate of ID 2340) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 2382 for deletion (duplicate of ID 2343) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 2509 for deletion (duplicate of ID 2349) with similarity 1.00 (threshold: 0.98)\n",
      "Marking message ID 2468 for deletion (duplicate of ID 2351) with similarity 0.96 (threshold: 0.95)\n",
      "Marking message ID 2470 for deletion (duplicate of ID 2352) with similarity 1.00 (threshold: 0.98)\n",
      "Marking message ID 2515 for deletion (duplicate of ID 2352) with similarity 1.00 (threshold: 0.98)\n",
      "Marking message ID 3680 for deletion (duplicate of ID 2413) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 2490 for deletion (duplicate of ID 2459) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 2489 for deletion (duplicate of ID 2460) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 2488 for deletion (duplicate of ID 2462) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 2719 for deletion (duplicate of ID 2650) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 2761 for deletion (duplicate of ID 2651) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 2747 for deletion (duplicate of ID 2652) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 2749 for deletion (duplicate of ID 2654) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 2751 for deletion (duplicate of ID 2656) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 2753 for deletion (duplicate of ID 2658) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 2755 for deletion (duplicate of ID 2660) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 2757 for deletion (duplicate of ID 2662) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 2759 for deletion (duplicate of ID 2664) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 2739 for deletion (duplicate of ID 2715) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 2873 for deletion (duplicate of ID 2771) with similarity 1.00 (threshold: 0.98)\n",
      "Marking message ID 2820 for deletion (duplicate of ID 2772) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 2808 for deletion (duplicate of ID 2773) with similarity 0.98 (threshold: 0.98)\n",
      "Marking message ID 2887 for deletion (duplicate of ID 2836) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 3203 for deletion (duplicate of ID 2836) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 3107 for deletion (duplicate of ID 2840) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 2897 for deletion (duplicate of ID 2847) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 3451 for deletion (duplicate of ID 2848) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 3453 for deletion (duplicate of ID 2850) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 3101 for deletion (duplicate of ID 2851) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 2885 for deletion (duplicate of ID 2853) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 3201 for deletion (duplicate of ID 2853) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 2899 for deletion (duplicate of ID 2867) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 2914 for deletion (duplicate of ID 2882) with similarity 0.99 (threshold: 0.9)\n",
      "Marking message ID 2913 for deletion (duplicate of ID 2883) with similarity 0.99 (threshold: 0.9)\n",
      "Marking message ID 3201 for deletion (duplicate of ID 2885) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 3203 for deletion (duplicate of ID 2887) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 4224 for deletion (duplicate of ID 2889) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 4316 for deletion (duplicate of ID 2889) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 4241 for deletion (duplicate of ID 2891) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 4269 for deletion (duplicate of ID 2891) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 3168 for deletion (duplicate of ID 2893) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 4267 for deletion (duplicate of ID 2893) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 4310 for deletion (duplicate of ID 2895) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 3180 for deletion (duplicate of ID 2922) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 3006 for deletion (duplicate of ID 2924) with similarity 1.00 (threshold: 0.98)\n",
      "Marking message ID 3186 for deletion (duplicate of ID 2924) with similarity 1.00 (threshold: 0.98)\n",
      "Marking message ID 2967 for deletion (duplicate of ID 2938) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 3095 for deletion (duplicate of ID 2941) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 3091 for deletion (duplicate of ID 2946) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 3038 for deletion (duplicate of ID 2948) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 3087 for deletion (duplicate of ID 2948) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 3213 for deletion (duplicate of ID 2958) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 2970 for deletion (duplicate of ID 2960) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 3008 for deletion (duplicate of ID 2963) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 3188 for deletion (duplicate of ID 2963) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 3292 for deletion (duplicate of ID 2963) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 3184 for deletion (duplicate of ID 2964) with similarity 1.00 (threshold: 0.98)\n",
      "Marking message ID 3024 for deletion (duplicate of ID 2984) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 3000 for deletion (duplicate of ID 2985) with similarity 0.99 (threshold: 0.9)\n",
      "Marking message ID 2998 for deletion (duplicate of ID 2987) with similarity 0.99 (threshold: 0.9)\n",
      "Marking message ID 3228 for deletion (duplicate of ID 2992) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 3050 for deletion (duplicate of ID 2994) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 3033 for deletion (duplicate of ID 3003) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 3193 for deletion (duplicate of ID 3003) with similarity 0.96 (threshold: 0.95)\n",
      "Marking message ID 3249 for deletion (duplicate of ID 3004) with similarity 0.92 (threshold: 0.9)\n",
      "Marking message ID 3186 for deletion (duplicate of ID 3006) with similarity 1.00 (threshold: 0.98)\n",
      "Marking message ID 3188 for deletion (duplicate of ID 3008) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 3292 for deletion (duplicate of ID 3008) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 3140 for deletion (duplicate of ID 3010) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 3138 for deletion (duplicate of ID 3012) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 3288 for deletion (duplicate of ID 3012) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 3026 for deletion (duplicate of ID 3017) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 3193 for deletion (duplicate of ID 3033) with similarity 0.96 (threshold: 0.95)\n",
      "Marking message ID 3085 for deletion (duplicate of ID 3036) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 3087 for deletion (duplicate of ID 3038) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 3093 for deletion (duplicate of ID 3044) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 3155 for deletion (duplicate of ID 3052) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 3253 for deletion (duplicate of ID 3060) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 3251 for deletion (duplicate of ID 3063) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 3276 for deletion (duplicate of ID 3064) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 3231 for deletion (duplicate of ID 3064) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 3158 for deletion (duplicate of ID 3065) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 3136 for deletion (duplicate of ID 3075) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 3286 for deletion (duplicate of ID 3075) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 4385 for deletion (duplicate of ID 3076) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 3120 for deletion (duplicate of ID 3083) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 3284 for deletion (duplicate of ID 3134) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 3286 for deletion (duplicate of ID 3136) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 3288 for deletion (duplicate of ID 3138) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 4267 for deletion (duplicate of ID 3168) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 3292 for deletion (duplicate of ID 3188) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 3276 for deletion (duplicate of ID 3231) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 3278 for deletion (duplicate of ID 3233) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 3308 for deletion (duplicate of ID 3242) with similarity 0.96 (threshold: 0.95)\n",
      "Marking message ID 3273 for deletion (duplicate of ID 3269) with similarity 0.99 (threshold: 0.95)\n",
      "Marking message ID 3366 for deletion (duplicate of ID 3312) with similarity 0.96 (threshold: 0.95)\n",
      "Marking message ID 3411 for deletion (duplicate of ID 3318) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 3436 for deletion (duplicate of ID 3318) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 6326 for deletion (duplicate of ID 3320) with similarity 1.00 (threshold: 0.98)\n",
      "Marking message ID 6337 for deletion (duplicate of ID 3320) with similarity 0.99 (threshold: 0.98)\n",
      "Marking message ID 6290 for deletion (duplicate of ID 3322) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 6339 for deletion (duplicate of ID 3322) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 3336 for deletion (duplicate of ID 3325) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 3413 for deletion (duplicate of ID 3385) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 3474 for deletion (duplicate of ID 3385) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 3436 for deletion (duplicate of ID 3411) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 3474 for deletion (duplicate of ID 3413) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 4471 for deletion (duplicate of ID 3450) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 4468 for deletion (duplicate of ID 3450) with similarity 0.97 (threshold: 0.95)\n",
      "Marking message ID 3571 for deletion (duplicate of ID 3518) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 3582 for deletion (duplicate of ID 3542) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 3641 for deletion (duplicate of ID 3585) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 3626 for deletion (duplicate of ID 3600) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 3623 for deletion (duplicate of ID 3621) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 3655 for deletion (duplicate of ID 3645) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 3671 for deletion (duplicate of ID 3645) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 3840 for deletion (duplicate of ID 3645) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 3865 for deletion (duplicate of ID 3645) with similarity 0.96 (threshold: 0.95)\n",
      "Marking message ID 3873 for deletion (duplicate of ID 3645) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 3663 for deletion (duplicate of ID 3654) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 3671 for deletion (duplicate of ID 3655) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 3840 for deletion (duplicate of ID 3655) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 3865 for deletion (duplicate of ID 3655) with similarity 0.96 (threshold: 0.95)\n",
      "Marking message ID 3873 for deletion (duplicate of ID 3655) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 3670 for deletion (duplicate of ID 3656) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 3836 for deletion (duplicate of ID 3658) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 3834 for deletion (duplicate of ID 3660) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 3840 for deletion (duplicate of ID 3671) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 3865 for deletion (duplicate of ID 3671) with similarity 0.96 (threshold: 0.95)\n",
      "Marking message ID 3873 for deletion (duplicate of ID 3671) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 3875 for deletion (duplicate of ID 3674) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 3693 for deletion (duplicate of ID 3676) with similarity 1.00 (threshold: 0.98)\n",
      "Marking message ID 3732 for deletion (duplicate of ID 3690) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 3944 for deletion (duplicate of ID 3690) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 3961 for deletion (duplicate of ID 3690) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 3945 for deletion (duplicate of ID 3691) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 3874 for deletion (duplicate of ID 3695) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 3930 for deletion (duplicate of ID 3697) with similarity 0.97 (threshold: 0.9)\n",
      "Marking message ID 3710 for deletion (duplicate of ID 3699) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 3929 for deletion (duplicate of ID 3707) with similarity 1.00 (threshold: 0.98)\n",
      "Marking message ID 3931 for deletion (duplicate of ID 3709) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 3877 for deletion (duplicate of ID 3709) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 3938 for deletion (duplicate of ID 3716) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 3762 for deletion (duplicate of ID 3722) with similarity 1.00 (threshold: 0.98)\n",
      "Marking message ID 3770 for deletion (duplicate of ID 3727) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 3826 for deletion (duplicate of ID 3727) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 3983 for deletion (duplicate of ID 3727) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 3982 for deletion (duplicate of ID 3728) with similarity 1.00 (threshold: 0.98)\n",
      "Marking message ID 3737 for deletion (duplicate of ID 3729) with similarity 1.00 (threshold: 0.98)\n",
      "Marking message ID 3824 for deletion (duplicate of ID 3729) with similarity 1.00 (threshold: 0.98)\n",
      "Marking message ID 4031 for deletion (duplicate of ID 3729) with similarity 1.00 (threshold: 0.98)\n",
      "Marking message ID 3959 for deletion (duplicate of ID 3730) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 3943 for deletion (duplicate of ID 3731) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 3944 for deletion (duplicate of ID 3732) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 3961 for deletion (duplicate of ID 3732) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 3824 for deletion (duplicate of ID 3737) with similarity 1.00 (threshold: 0.98)\n",
      "Marking message ID 4031 for deletion (duplicate of ID 3737) with similarity 1.00 (threshold: 0.98)\n",
      "Marking message ID 3980 for deletion (duplicate of ID 3742) with similarity 0.98 (threshold: 0.98)\n",
      "Marking message ID 3957 for deletion (duplicate of ID 3743) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 3942 for deletion (duplicate of ID 3744) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 3969 for deletion (duplicate of ID 3744) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 3909 for deletion (duplicate of ID 3758) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 3772 for deletion (duplicate of ID 3759) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 3828 for deletion (duplicate of ID 3759) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 3985 for deletion (duplicate of ID 3759) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 4035 for deletion (duplicate of ID 3759) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 3813 for deletion (duplicate of ID 3766) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 5890 for deletion (duplicate of ID 3766) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 3826 for deletion (duplicate of ID 3770) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 3983 for deletion (duplicate of ID 3770) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 3828 for deletion (duplicate of ID 3772) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 3985 for deletion (duplicate of ID 3772) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 4035 for deletion (duplicate of ID 3772) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 3986 for deletion (duplicate of ID 3773) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 3830 for deletion (duplicate of ID 3774) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 3859 for deletion (duplicate of ID 3774) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 3967 for deletion (duplicate of ID 3785) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 3941 for deletion (duplicate of ID 3786) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 4821 for deletion (duplicate of ID 3807) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 4855 for deletion (duplicate of ID 3809) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 5890 for deletion (duplicate of ID 3813) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 3850 for deletion (duplicate of ID 3820) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 4043 for deletion (duplicate of ID 3820) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 3964 for deletion (duplicate of ID 3822) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 4031 for deletion (duplicate of ID 3824) with similarity 1.00 (threshold: 0.98)\n",
      "Marking message ID 3983 for deletion (duplicate of ID 3826) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 3985 for deletion (duplicate of ID 3828) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 4035 for deletion (duplicate of ID 3828) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 3859 for deletion (duplicate of ID 3830) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 4012 for deletion (duplicate of ID 3831) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 3861 for deletion (duplicate of ID 3832) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 4013 for deletion (duplicate of ID 3832) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 3865 for deletion (duplicate of ID 3840) with similarity 0.96 (threshold: 0.95)\n",
      "Marking message ID 3873 for deletion (duplicate of ID 3840) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 3988 for deletion (duplicate of ID 3842) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 3990 for deletion (duplicate of ID 3844) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 3992 for deletion (duplicate of ID 3846) with similarity 0.98 (threshold: 0.9)\n",
      "Marking message ID 4019 for deletion (duplicate of ID 3849) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 4043 for deletion (duplicate of ID 3850) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 4021 for deletion (duplicate of ID 3851) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 4045 for deletion (duplicate of ID 3852) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 4013 for deletion (duplicate of ID 3861) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 3931 for deletion (duplicate of ID 3877) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 3969 for deletion (duplicate of ID 3942) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 3961 for deletion (duplicate of ID 3944) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 4066 for deletion (duplicate of ID 3951) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 4068 for deletion (duplicate of ID 3953) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 4035 for deletion (duplicate of ID 3985) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 4161 for deletion (duplicate of ID 4048) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 4082 for deletion (duplicate of ID 4051) with similarity 0.96 (threshold: 0.95)\n",
      "Marking message ID 4152 for deletion (duplicate of ID 4055) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 4134 for deletion (duplicate of ID 4073) with similarity 0.98 (threshold: 0.95)\n",
      "Marking message ID 6372 for deletion (duplicate of ID 4126) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 6371 for deletion (duplicate of ID 4127) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 4146 for deletion (duplicate of ID 4132) with similarity 1.00 (threshold: 0.98)\n",
      "Marking message ID 4219 for deletion (duplicate of ID 4132) with similarity 1.00 (threshold: 0.98)\n",
      "Marking message ID 4201 for deletion (duplicate of ID 4137) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 4219 for deletion (duplicate of ID 4146) with similarity 1.00 (threshold: 0.98)\n",
      "Marking message ID 5222 for deletion (duplicate of ID 4194) with similarity 0.99 (threshold: 0.95)\n",
      "Marking message ID 4316 for deletion (duplicate of ID 4224) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 4252 for deletion (duplicate of ID 4233) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 4257 for deletion (duplicate of ID 4234) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 5422 for deletion (duplicate of ID 4234) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 4285 for deletion (duplicate of ID 4240) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 5453 for deletion (duplicate of ID 4240) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 4269 for deletion (duplicate of ID 4241) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 4260 for deletion (duplicate of ID 4244) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 5465 for deletion (duplicate of ID 4255) with similarity 0.99 (threshold: 0.95)\n",
      "Marking message ID 5422 for deletion (duplicate of ID 4257) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 5453 for deletion (duplicate of ID 4285) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 4382 for deletion (duplicate of ID 4291) with similarity 1.00 (threshold: 0.98)\n",
      "Marking message ID 5510 for deletion (duplicate of ID 4291) with similarity 1.00 (threshold: 0.98)\n",
      "Marking message ID 5530 for deletion (duplicate of ID 4291) with similarity 1.00 (threshold: 0.98)\n",
      "Marking message ID 4351 for deletion (duplicate of ID 4293) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 4358 for deletion (duplicate of ID 4331) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 4360 for deletion (duplicate of ID 4333) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 4393 for deletion (duplicate of ID 4339) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 4445 for deletion (duplicate of ID 4339) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 5493 for deletion (duplicate of ID 4339) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 5503 for deletion (duplicate of ID 4363) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 6561 for deletion (duplicate of ID 4369) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 5526 for deletion (duplicate of ID 4378) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 5528 for deletion (duplicate of ID 4380) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 5488 for deletion (duplicate of ID 4381) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 5510 for deletion (duplicate of ID 4382) with similarity 1.00 (threshold: 0.98)\n",
      "Marking message ID 5530 for deletion (duplicate of ID 4382) with similarity 1.00 (threshold: 0.98)\n",
      "Marking message ID 4433 for deletion (duplicate of ID 4388) with similarity 0.99 (threshold: 0.95)\n",
      "Marking message ID 4449 for deletion (duplicate of ID 4389) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 4462 for deletion (duplicate of ID 4389) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 5543 for deletion (duplicate of ID 4389) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 5515 for deletion (duplicate of ID 4390) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 4447 for deletion (duplicate of ID 4391) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 5619 for deletion (duplicate of ID 4391) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 5494 for deletion (duplicate of ID 4392) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 4445 for deletion (duplicate of ID 4393) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 5493 for deletion (duplicate of ID 4393) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 4519 for deletion (duplicate of ID 4394) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 4437 for deletion (duplicate of ID 4398) with similarity 1.00 (threshold: 0.98)\n",
      "Marking message ID 5520 for deletion (duplicate of ID 4401) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 5492 for deletion (duplicate of ID 4436) with similarity 1.00 (threshold: 0.98)\n",
      "Marking message ID 5627 for deletion (duplicate of ID 4439) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 5493 for deletion (duplicate of ID 4445) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 5619 for deletion (duplicate of ID 4447) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 4462 for deletion (duplicate of ID 4449) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 5543 for deletion (duplicate of ID 4449) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 5544 for deletion (duplicate of ID 4450) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 4464 for deletion (duplicate of ID 4451) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 5623 for deletion (duplicate of ID 4451) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 5543 for deletion (duplicate of ID 4462) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 5623 for deletion (duplicate of ID 4464) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 5624 for deletion (duplicate of ID 4465) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 4471 for deletion (duplicate of ID 4468) with similarity 0.97 (threshold: 0.95)\n",
      "Marking message ID 4484 for deletion (duplicate of ID 4472) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 5570 for deletion (duplicate of ID 4476) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 4503 for deletion (duplicate of ID 4481) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 4493 for deletion (duplicate of ID 4483) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 4494 for deletion (duplicate of ID 4485) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 4509 for deletion (duplicate of ID 4488) with similarity 0.99 (threshold: 0.95)\n",
      "Marking message ID 4549 for deletion (duplicate of ID 4491) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 5629 for deletion (duplicate of ID 4491) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 5600 for deletion (duplicate of ID 4495) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 4546 for deletion (duplicate of ID 4500) with similarity 1.00 (threshold: 0.98)\n",
      "Marking message ID 5615 for deletion (duplicate of ID 4512) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 5633 for deletion (duplicate of ID 4522) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 6150 for deletion (duplicate of ID 4522) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 6502 for deletion (duplicate of ID 4522) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 4596 for deletion (duplicate of ID 4540) with similarity 0.99 (threshold: 0.95)\n",
      "Marking message ID 5629 for deletion (duplicate of ID 4549) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 4565 for deletion (duplicate of ID 4551) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 5631 for deletion (duplicate of ID 4551) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 4585 for deletion (duplicate of ID 4556) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 4632 for deletion (duplicate of ID 4557) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 5631 for deletion (duplicate of ID 4565) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 5655 for deletion (duplicate of ID 4576) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 4616 for deletion (duplicate of ID 4587) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 4618 for deletion (duplicate of ID 4589) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 4639 for deletion (duplicate of ID 4589) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 4602 for deletion (duplicate of ID 4593) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 4634 for deletion (duplicate of ID 4593) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 4634 for deletion (duplicate of ID 4602) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 5783 for deletion (duplicate of ID 4610) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 5779 for deletion (duplicate of ID 4612) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 4639 for deletion (duplicate of ID 4618) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 4659 for deletion (duplicate of ID 4626) with similarity 1.00 (threshold: 0.98)\n",
      "Marking message ID 4650 for deletion (duplicate of ID 4628) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 4673 for deletion (duplicate of ID 4638) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 5695 for deletion (duplicate of ID 4688) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 4701 for deletion (duplicate of ID 4692) with similarity 1.00 (threshold: 0.98)\n",
      "Marking message ID 4790 for deletion (duplicate of ID 4694) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 4751 for deletion (duplicate of ID 4714) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 4723 for deletion (duplicate of ID 4720) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 4743 for deletion (duplicate of ID 4725) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 4758 for deletion (duplicate of ID 4727) with similarity 0.98 (threshold: 0.95)\n",
      "Marking message ID 5703 for deletion (duplicate of ID 4735) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 4764 for deletion (duplicate of ID 4738) with similarity 0.99 (threshold: 0.95)\n",
      "Marking message ID 4775 for deletion (duplicate of ID 4747) with similarity 0.99 (threshold: 0.95)\n",
      "Marking message ID 4780 for deletion (duplicate of ID 4756) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 4781 for deletion (duplicate of ID 4757) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 4797 for deletion (duplicate of ID 4769) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 4814 for deletion (duplicate of ID 4769) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 5775 for deletion (duplicate of ID 4771) with similarity 0.99 (threshold: 0.95)\n",
      "Marking message ID 5730 for deletion (duplicate of ID 4779) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 4815 for deletion (duplicate of ID 4784) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 4863 for deletion (duplicate of ID 4793) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 4887 for deletion (duplicate of ID 4796) with similarity 0.99 (threshold: 0.9)\n",
      "Marking message ID 4814 for deletion (duplicate of ID 4797) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 5793 for deletion (duplicate of ID 4800) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 5050 for deletion (duplicate of ID 4869) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 5116 for deletion (duplicate of ID 4901) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 5847 for deletion (duplicate of ID 4902) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 4985 for deletion (duplicate of ID 4917) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 4987 for deletion (duplicate of ID 4919) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 5805 for deletion (duplicate of ID 4920) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 5831 for deletion (duplicate of ID 4926) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 5856 for deletion (duplicate of ID 4943) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 5858 for deletion (duplicate of ID 4945) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 5860 for deletion (duplicate of ID 4947) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 5863 for deletion (duplicate of ID 4950) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 5811 for deletion (duplicate of ID 4970) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 5126 for deletion (duplicate of ID 5011) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 5077 for deletion (duplicate of ID 5013) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 5904 for deletion (duplicate of ID 5013) with similarity 0.98 (threshold: 0.9)\n",
      "Marking message ID 5034 for deletion (duplicate of ID 5015) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 5906 for deletion (duplicate of ID 5015) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 5908 for deletion (duplicate of ID 5017) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 5906 for deletion (duplicate of ID 5034) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 5130 for deletion (duplicate of ID 5035) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 5185 for deletion (duplicate of ID 5036) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 5103 for deletion (duplicate of ID 5039) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 5105 for deletion (duplicate of ID 5041) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 5124 for deletion (duplicate of ID 5055) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 5084 for deletion (duplicate of ID 5058) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 5955 for deletion (duplicate of ID 5058) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 5133 for deletion (duplicate of ID 5064) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 5163 for deletion (duplicate of ID 5066) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 5923 for deletion (duplicate of ID 5066) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 5904 for deletion (duplicate of ID 5077) with similarity 0.98 (threshold: 0.9)\n",
      "Marking message ID 5955 for deletion (duplicate of ID 5084) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 5953 for deletion (duplicate of ID 5086) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 5194 for deletion (duplicate of ID 5090) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 5269 for deletion (duplicate of ID 5090) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 5273 for deletion (duplicate of ID 5094) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 5247 for deletion (duplicate of ID 5095) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 5201 for deletion (duplicate of ID 5097) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 5277 for deletion (duplicate of ID 5098) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 5203 for deletion (duplicate of ID 5099) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 5278 for deletion (duplicate of ID 5099) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 5921 for deletion (duplicate of ID 5134) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 5875 for deletion (duplicate of ID 5156) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 5923 for deletion (duplicate of ID 5163) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 5902 for deletion (duplicate of ID 5165) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 5238 for deletion (duplicate of ID 5190) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 5269 for deletion (duplicate of ID 5194) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 5278 for deletion (duplicate of ID 5203) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 5293 for deletion (duplicate of ID 5263) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 5355 for deletion (duplicate of ID 5314) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 5346 for deletion (duplicate of ID 5331) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 6444 for deletion (duplicate of ID 5340) with similarity 0.99 (threshold: 0.95)\n",
      "Marking message ID 5390 for deletion (duplicate of ID 5349) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 5389 for deletion (duplicate of ID 5350) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 5441 for deletion (duplicate of ID 5350) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 5994 for deletion (duplicate of ID 5350) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 6080 for deletion (duplicate of ID 5350) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 5974 for deletion (duplicate of ID 5357) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 5406 for deletion (duplicate of ID 5358) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 5395 for deletion (duplicate of ID 5360) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 6112 for deletion (duplicate of ID 5383) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 5446 for deletion (duplicate of ID 5384) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 5439 for deletion (duplicate of ID 5387) with similarity 0.99 (threshold: 0.9)\n",
      "Marking message ID 5992 for deletion (duplicate of ID 5387) with similarity 0.99 (threshold: 0.9)\n",
      "Marking message ID 6078 for deletion (duplicate of ID 5387) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 5441 for deletion (duplicate of ID 5389) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 5994 for deletion (duplicate of ID 5389) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 6080 for deletion (duplicate of ID 5389) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 6021 for deletion (duplicate of ID 5403) with similarity 0.96 (threshold: 0.95)\n",
      "Marking message ID 6023 for deletion (duplicate of ID 5405) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 6114 for deletion (duplicate of ID 5410) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 5448 for deletion (duplicate of ID 5411) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 5466 for deletion (duplicate of ID 5423) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 5436 for deletion (duplicate of ID 5424) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 5992 for deletion (duplicate of ID 5439) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 6078 for deletion (duplicate of ID 5439) with similarity 0.99 (threshold: 0.9)\n",
      "Marking message ID 5994 for deletion (duplicate of ID 5441) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 6080 for deletion (duplicate of ID 5441) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 6116 for deletion (duplicate of ID 5449) with similarity 1.00 (threshold: 0.98)\n",
      "Marking message ID 5533 for deletion (duplicate of ID 5450) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 5530 for deletion (duplicate of ID 5510) with similarity 1.00 (threshold: 0.98)\n",
      "Marking message ID 6118 for deletion (duplicate of ID 5532) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 6120 for deletion (duplicate of ID 5588) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 5750 for deletion (duplicate of ID 5602) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 5772 for deletion (duplicate of ID 5602) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 6150 for deletion (duplicate of ID 5633) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 6502 for deletion (duplicate of ID 5633) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 6522 for deletion (duplicate of ID 5648) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 5753 for deletion (duplicate of ID 5673) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 5755 for deletion (duplicate of ID 5675) with similarity 0.97 (threshold: 0.95)\n",
      "Marking message ID 5768 for deletion (duplicate of ID 5675) with similarity 0.95 (threshold: 0.95)\n",
      "Marking message ID 5828 for deletion (duplicate of ID 5733) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 5772 for deletion (duplicate of ID 5750) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 5768 for deletion (duplicate of ID 5755) with similarity 0.98 (threshold: 0.95)\n",
      "Marking message ID 5803 for deletion (duplicate of ID 5787) with similarity 1.00 (threshold: 0.98)\n",
      "Marking message ID 5916 for deletion (duplicate of ID 5807) with similarity 0.97 (threshold: 0.9)\n",
      "Marking message ID 5915 for deletion (duplicate of ID 5808) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 5842 for deletion (duplicate of ID 5821) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 6078 for deletion (duplicate of ID 5992) with similarity 0.99 (threshold: 0.9)\n",
      "Marking message ID 6080 for deletion (duplicate of ID 5994) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 6104 for deletion (duplicate of ID 6103) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 6502 for deletion (duplicate of ID 6150) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 6285 for deletion (duplicate of ID 6195) with similarity 1.00 (threshold: 0.98)\n",
      "Marking message ID 6416 for deletion (duplicate of ID 6202) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 6378 for deletion (duplicate of ID 6261) with similarity 0.98 (threshold: 0.95)\n",
      "Marking message ID 6339 for deletion (duplicate of ID 6290) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 6358 for deletion (duplicate of ID 6323) with similarity 0.99 (threshold: 0.9)\n",
      "Marking message ID 6337 for deletion (duplicate of ID 6326) with similarity 0.99 (threshold: 0.98)\n",
      "Marking message ID 6341 for deletion (duplicate of ID 6328) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 6352 for deletion (duplicate of ID 6329) with similarity 0.98 (threshold: 0.95)\n",
      "Marking message ID 6420 for deletion (duplicate of ID 6379) with similarity 0.98 (threshold: 0.95)\n",
      "Marking message ID 6495 for deletion (duplicate of ID 6385) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 6439 for deletion (duplicate of ID 6386) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 6465 for deletion (duplicate of ID 6387) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 6410 for deletion (duplicate of ID 6387) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 6437 for deletion (duplicate of ID 6388) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 6463 for deletion (duplicate of ID 6389) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 6408 for deletion (duplicate of ID 6389) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 6435 for deletion (duplicate of ID 6390) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 6546 for deletion (duplicate of ID 6403) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 6461 for deletion (duplicate of ID 6406) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 6463 for deletion (duplicate of ID 6408) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 6465 for deletion (duplicate of ID 6410) with similarity 1.00 (threshold: 0.95)\n",
      "Marking message ID 6467 for deletion (duplicate of ID 6412) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 6510 for deletion (duplicate of ID 6431) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 6459 for deletion (duplicate of ID 6432) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 6488 for deletion (duplicate of ID 6433) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 6507 for deletion (duplicate of ID 6455) with similarity 1.00 (threshold: 0.9)\n",
      "Marking message ID 6485 for deletion (duplicate of ID 6457) with similarity 0.99 (threshold: 0.9)\n",
      "Marking message ID 6508 for deletion (duplicate of ID 6484) with similarity 1.00 (threshold: 0.9)\n",
      "Deleted 572 duplicate messages.\n",
      "Remaining messages: 4272\n"
     ]
    }
   ],
   "source": [
    "# remove duplicate messages: improved version with HTML cleaning and adaptive thresholds\n",
    "conn = sqlite3.connect(DB_PATH)\n",
    "cursor = conn.cursor()\n",
    "query = '''\n",
    "SELECT m1.id, m1.source_filename, m1.from_address, m1.to_address, m1.timestamp_iso, m1.message_html,\n",
    "       m2.id, m2.source_filename, m2.from_address, m2.to_address, m2.timestamp_iso, m2.message_html\n",
    "FROM messages m1\n",
    "JOIN messages m2 ON m1.from_address = m2.from_address AND m1.to_address = m2.to_address AND m1.id < m2.id\n",
    "'''\n",
    "cursor.execute(query)\n",
    "rows = cursor.fetchall()\n",
    "ids_to_delete = set()\n",
    "for row in rows:\n",
    "    msg1_html = row[5]\n",
    "    msg2_html = row[11]\n",
    "    time1_str = row[4]\n",
    "    time2_str = row[10]\n",
    "    \n",
    "    # Parse timestamps properly\n",
    "    try:\n",
    "        time1 = datetime.strptime(time1_str, '%Y%m%d%H%M%S')\n",
    "        time2 = datetime.strptime(time2_str, '%Y%m%d%H%M%S')\n",
    "    except:\n",
    "        print(f\"Invalid timestamp format for message IDs {row[0]} and {row[6]}: '{time1_str}' or '{time2_str}'\")\n",
    "        continue  # Skip if timestamp format is invalid\n",
    "    \n",
    "    # Calculate time difference in minutes\n",
    "    time_diff_minutes = abs((time2 - time1).total_seconds()) / 60\n",
    "    \n",
    "    if time_diff_minutes <= 1450:\n",
    "        # Clean HTML tags and normalize whitespace before comparison\n",
    "        cleaned_msg1 = clean_html_for_comparison(msg1_html)\n",
    "        cleaned_msg2 = clean_html_for_comparison(msg2_html)\n",
    "        \n",
    "        # Determine adaptive threshold based on message length\n",
    "        cleaned_len = len(cleaned_msg1)\n",
    "        if cleaned_len < 100:\n",
    "            threshold = 0.90  # More lenient for short messages\n",
    "        elif cleaned_len < 500:\n",
    "            threshold = 0.95\n",
    "        else:\n",
    "            threshold = 0.98  # Stricter for longer messages\n",
    "        \n",
    "        # Check similarity on cleaned text\n",
    "        similarity = difflib.SequenceMatcher(None, cleaned_msg1, cleaned_msg2).ratio()\n",
    "        if similarity >= threshold:\n",
    "            ids_to_delete.add(row[6])  # delete the second message\n",
    "            print(f\"Marking message ID {row[6]} for deletion (duplicate of ID {row[0]}) with similarity {similarity:.2f} (threshold: {threshold})\")\n",
    "\n",
    "# Delete identified duplicates\n",
    "if ids_to_delete:\n",
    "    delete_query = f'''\n",
    "    DELETE FROM messages\n",
    "    WHERE id IN ({','.join(['?']*len(ids_to_delete))})\n",
    "    '''\n",
    "    cursor.execute(delete_query, tuple(ids_to_delete))\n",
    "    conn.commit()\n",
    "    print(f\"Deleted {len(ids_to_delete)} duplicate messages.\")\n",
    "else:\n",
    "    print(\"No duplicates found to delete.\")\n",
    "\n",
    "conn.close()\n",
    "\n",
    "# print remaining number of messages\n",
    "conn = sqlite3.connect(DB_PATH)\n",
    "query = '''\n",
    "SELECT *    \n",
    "FROM messages\n",
    "'''\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(query)\n",
    "remaining_messages = cursor.fetchall()\n",
    "print(f\"Remaining messages: {len(remaining_messages)}\")\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qwen 2.5 VL 72B\n",
    "Remaining messages: 5557\n",
    "with html tags removed for comparing and set to 24h: remaining messages 4377\n",
    "\n",
    "251123: Remaining messages: 4335 (updated prompt)\n",
    "3997: Resolved a lot of redacted messages\n",
    "\n",
    "20251125: \n",
    "qwen3 vl 30ba3:\n",
    "Deleted 1192 duplicate messages.\n",
    "Remaining messages: 4271\n",
    "Qwen 2.5 VL 72B\n",
    "Deleted 1733 + 572 duplicate messages.\n",
    "Remaining messages: 4272"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of messages after cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top Email Addresses:\n",
      "Jeffrey Epstein: 4033\n",
      "Michael Wolff: 251\n",
      "Weingarten, Reid: 241\n",
      "Kathy Ruemmler: 201\n",
      "Lawrence Summers: 167\n",
      "Landon Thomas Jr.: 154\n",
      "Richard Kahn: 151\n",
      "Steve Bannon: 119\n",
      "<REDACTED>: 98\n",
      "Darren Indyke: 85\n",
      "Lawrence Krauss: 79\n",
      "Nicholas Ribis: 71\n",
      "Martin Weinberg: 63\n",
      "Robert Kuhn: 59\n",
      "Lisa New: 58\n",
      "Larry Visoski: 49\n",
      "Lesley Groff: 47\n",
      "Boris Nikolic: 43\n",
      "Joi Ito: 40\n",
      "Deepak Chopra: 39\n",
      "Ken Starr: 38\n",
      "paul krassner: 33\n",
      "Peggy Siegal: 33\n",
      "Jonathan Farkas: 30\n",
      "Noam Chomsky: 29\n",
      "Anas Alrasheed: 29\n",
      "Sultan Bin Sulayem: 28\n",
      "Robert Trivers: 26\n",
      "Pritzker, Tom: 26\n",
      "David Schoen: 23\n",
      "Zubair Khan: 22\n",
      "Linda Stone: 21\n",
      "Masha Drokova: 21\n",
      "Tonja Haddad Coleman: 20\n",
      "Jessica Cadwell: 19\n",
      "Thorbjon Jagland: 19\n",
      "Ehud Barak: 19\n",
      "David Stern: 18\n",
      "Tyler Shears: 18\n",
      "Faith Kates: 17\n",
      "David Grosof: 17\n",
      "Jabor Y.: 17\n",
      "steven hoffenberg: 16\n",
      "Alireza Ittihadieh: 16\n",
      "habebey: 16\n",
      "Michael Wolff < >: 15\n",
      "LHS < >: 15\n",
      "Ens, Amanda: 14\n",
      "Etienne Binant: 14\n",
      "Jacquie Johnson: 14\n",
      "tamem: 14\n",
      "live:linkspirit: 14\n",
      "Steven Pfeiffer: 13\n",
      "Ariane de Rothschild: 13\n",
      "Jay Lefkowitz: 12\n",
      "Christina Galbraith: 12\n",
      "Barry J. Cohen: 12\n",
      "Nowak, Martin A.: 12\n",
      "Fred Haddad: 12\n",
      "anasalrasheed: 11\n",
      "Lawrence Krauss <lkrauss@asu.edu>: 11\n",
      "Karp, Brad S: 11\n",
      "anasalrasheed@gmail.com: 11\n",
      "Jack Goldberger: 11\n",
      "Lang, Caroline: 11\n",
      "Bruce Moskowitz: 10\n",
      "Larry: 10\n",
      "Rebecca Watson: 10\n",
      "Paul Barrett: 10\n",
      "Peter Thiel: 10\n",
      "Dangene and Jennie Enterprise: 9\n",
      "Miller, Michael: 9\n",
      "Mark L. Epstein: 9\n",
      "DAVID SCHOEN: 9\n",
      "Al seckel: 9\n",
      "< >: 9\n",
      "Stanley Rosenberg: 9\n",
      "Sheikh: 9\n",
      "Richard Merkin: 9\n",
      "Jakob Kollhofer: 9\n",
      "Alan Dershowitz: 9\n",
      "Stephen Hanson: 9\n",
      "Nadia <nadja2102@yahoo.com>: 9\n",
      "Melanie Spinella: 9\n",
      "Landon Thomas: 9\n",
      "Larry Summers < >: 8\n",
      "Soon-Yi: 8\n",
      "Roy Black: 8\n",
      "Eric Roth: 8\n",
      "Melanie Walker: 8\n",
      "Jide Zeitlin: 8\n",
      "Peter Mandelson: 8\n",
      "Mohamed Waheed Hassan: 8\n",
      "Jeffrey: 8\n",
      "Michael Wolff <>: 7\n",
      "Google Alerts <googlealerts-noreply@google.com>: 7\n",
      "Brandon Thompson: 7\n",
      "elisabeth feliho: 7\n",
      "Valeria Chomsky: 7\n",
      "Jack LANG: 7\n"
     ]
    }
   ],
   "source": [
    "# find all unique from addresses \n",
    "conn = sqlite3.connect(DB_PATH) \n",
    "query = '''\n",
    "SELECT from_address, COUNT(*) as count\n",
    "FROM messages\n",
    "GROUP BY from_address\n",
    "ORDER BY count DESC\n",
    "'''\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(query)\n",
    "results_from = cursor.fetchall()\n",
    "conn.close()\n",
    "# find all unique to addresses \n",
    "conn = sqlite3.connect(DB_PATH) \n",
    "query = '''\n",
    "SELECT to_address, COUNT(*) as count\n",
    "FROM messages\n",
    "GROUP BY to_address\n",
    "ORDER BY count DESC\n",
    "'''\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(query)\n",
    "results_to = cursor.fetchall()\n",
    "conn.close()\n",
    "# add both from and to addresses together and display top 100\n",
    "from collections import defaultdict\n",
    "address_counts = defaultdict(int)\n",
    "for address, count in results_from:\n",
    "    address_counts[address] += count\n",
    "for address, count in results_to:\n",
    "    address_counts[address] += count   \n",
    "results = sorted(address_counts.items(), key=lambda x: x[1], reverse=True) \n",
    "# Display the top results\n",
    "print(\"\\nTop Email Addresses:\")\n",
    "for address, count in results[:100]:\n",
    "    print(f\"{address}: {count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "still some addresses i left out for the moment:\n",
    "    'Jeffrey',\n",
    "        '< >',\n",
    "            'live:linkspirit',\n",
    "    'soon yi previn' =    'Soon-Yi', ?\n",
    "    'Google Alerts <googlealerts-noreply@google.com>',\n",
    "        'Kathy Ruemmle' =     'Kathy Ruemmler'?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save jpg sources\n",
    "\n",
    "all messages are linked to a jpg, get it, resize it and put it under \\data\\sources\\ with same filename, so it is easily accesble through the gui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 4272 document ids for image extraction and resizing\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_019307.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_019318.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_019313.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_019314.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_019328.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_021405.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_020661.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_022192.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_019339.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_022194.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_022264.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_022231.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_022228.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_022229.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_022775.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_022826.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_022779.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_022828.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_022836.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_022833.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_022948.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_023025.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_022842.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_022843.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_023027.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_022930.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_025167.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_025168.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_025165.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_025198.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_025130.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_025177.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_025173.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_025656.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_025106.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_025107.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_025108.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_025109.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_025538.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_025111.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_025112.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_025191.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_025936.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_025968.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_026021.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_026050.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_025897.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_026109.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_026133.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_026087.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_026124.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_026125.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_026091.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_026175.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_026177.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_026181.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_026185.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_026189.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_026190.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_026236.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_026264.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_026226.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_026194.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_026357.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_026373.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_026374.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_026375.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_026467.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_026423.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_026836.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_027054.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_027040.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_028754.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_028502.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_028871.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_028872.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_028873.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_028874.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_028932.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_028886.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_028868.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_029008.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_028981.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_028982.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_029233.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_029243.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_029244.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_029270.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_029151.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_029152.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_029256.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_029127.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_029275.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_029249.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_029599.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_029607.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_029594.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_029838.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_029855.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_029686.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_029984.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_030114.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_030404.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_030588.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_030345.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_030471.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_030642.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_030479.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_030685.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_030692.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_030704.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_030695.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_030697.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_030698.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_030749.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_030747.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_030753.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_030776.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_030803.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_030996.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_031003.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_031037.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_030984.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_030917.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_031006.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_031214.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_031132.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_031023.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_031222.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_031231.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_031232.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_031285.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_031322.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_031348.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_031351.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_031352.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_031502.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_031506.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_031551.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_031550.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_031515.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_031620.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_031687.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_031685.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_031797.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_031810.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_032247.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_032249.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_032291.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_032295.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_032327.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_032328.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_032454.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_032468.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_032493.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_032580.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_032632.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_032653.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_032596.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_032656.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_032664.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_032612.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_032661.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_032668.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_032740.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_032763.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_032794.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_032866.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_032909.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_032991.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_032922.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_032923.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_032993.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_032986.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_032987.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_033049.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_033086.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_033135.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_033465.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_033439.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_033461.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_033462.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_033441.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_033442.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_033575.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_033581.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_033591.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_033592.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_033590.jpg\n",
      "Saved resized image to data\\sources\\HOUSE_OVERSIGHT_033562.jpg\n"
     ]
    }
   ],
   "source": [
    "# for each message, get the source_filename\n",
    "# if the same filename but with extension .jpg does not yet exist under .\\data\\sources\\\n",
    "# search the same filename but with extension .jpg in the DATASET_ROOT/IMAGES (beware it has subfolders)\n",
    "# resize this image to height 800px, maintain aspect ratio, quality 60\n",
    "# save with same filename under .\\data\\sources\\\n",
    "conn = sqlite3.connect(DB_PATH)\n",
    "query = '''\n",
    "SELECT document_id\n",
    "FROM messages\n",
    "'''\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(query)\n",
    "results = cursor.fetchall()\n",
    "print(f\"Processing {len(results)} document ids for image extraction and resizing\")\n",
    "for row in results:\n",
    "    document_id = row[0]\n",
    "    # Remove existing extension (if any) before adding .jpg\n",
    "    document_id_base = Path(document_id).stem\n",
    "    source_image_path = Path('data/sources') / (document_id_base + '.jpg')\n",
    "    if not source_image_path.exists():\n",
    "        # search in DATASET_ROOT/IMAGES\n",
    "        images_dir = DATASET_ROOT / 'IMAGES'\n",
    "        pattern = f\"**/{document_id_base}.jpg\"\n",
    "        matching_files = list(images_dir.glob(pattern))\n",
    "        if matching_files:\n",
    "            image_path = matching_files[0]\n",
    "            # resize and save\n",
    "            img = Image.open(image_path)\n",
    "            aspect_ratio = img.width / img.height\n",
    "            new_height = 800\n",
    "            new_width = int(aspect_ratio * new_height)\n",
    "            img_resized = img.resize((new_width, new_height), Image.Resampling.LANCZOS)\n",
    "            os.makedirs(source_image_path.parent, exist_ok=True)\n",
    "            img_resized.save(source_image_path, format='JPEG', quality=60)\n",
    "            print(f\"Saved resized image to {source_image_path}\")\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimise DB size. This will:\n",
    "\n",
    "0. ✅ Take a backup of the dv with extension `.before_optimization`\n",
    "1. ✅ Create a new optimized `messages` table with only the 6 columns your GUI actually uses\n",
    "2. ✅ Copy all data to the new table\n",
    "3. ✅ Drop the old table and rename the new one\n",
    "4. ✅ Recreate necessary indexes (I added indexes for `from_address` and `to_address` too for better query performance)\n",
    "5. ✅ Drop the completely unused `email_documents` table\n",
    "6. ✅ Run VACUUM to compress and defragment\n",
    "7. ✅ Show the before/after size comparison\n",
    "\n",
    "This should give a __30-50% size reduction__ depending on how much data was in those unused columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting database optimization...\n",
      "\n",
      "Dropping unused columns from messages table...\n",
      "Recreating indexes...\n",
      "Dropping unused email_documents table...\n",
      "Running VACUUM to compress database...\n",
      "\n",
      "==================================================\n",
      "Database Optimization Complete!\n",
      "==================================================\n",
      "Initial size:  4,844.0 KB\n",
      "Final size:    2,760.0 KB\n",
      "Reduction:     43.0% (2,084.0 KB saved)\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "## Database Optimization and Compression\n",
    "print(\"Starting database optimization...\")\n",
    "\n",
    "# first take a copy of the database for safety\n",
    "import shutil\n",
    "shutil.copyfile(DB_PATH, DB_PATH + '.before_optimization')\n",
    "conn = sqlite3.connect(DB_PATH)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Get initial database size\n",
    "initial_size = os.path.getsize(DB_PATH) / 1024  # KB\n",
    "\n",
    "# Drop unused columns from messages table\n",
    "print(\"\\nDropping unused columns from messages table...\")\n",
    "cursor.execute('''\n",
    "CREATE TABLE messages_optimized (\n",
    "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    from_address TEXT,\n",
    "    to_address TEXT,\n",
    "    timestamp_iso TEXT,\n",
    "    subject TEXT,\n",
    "    message_html TEXT,\n",
    "    document_id TEXT\n",
    ")\n",
    "''')\n",
    "\n",
    "cursor.execute('''\n",
    "INSERT INTO messages_optimized (id, from_address, to_address, timestamp_iso, subject, message_html, document_id)\n",
    "SELECT id, from_address, to_address, timestamp_iso, subject, message_html, document_id\n",
    "FROM messages\n",
    "''')\n",
    "\n",
    "cursor.execute('DROP TABLE messages')\n",
    "cursor.execute('ALTER TABLE messages_optimized RENAME TO messages')\n",
    "\n",
    "# Recreate indexes on optimized table\n",
    "print(\"Recreating indexes...\")\n",
    "cursor.execute('CREATE INDEX idx_messages_timestamp ON messages(timestamp_iso)')\n",
    "cursor.execute('CREATE INDEX idx_messages_from ON messages(from_address)')\n",
    "cursor.execute('CREATE INDEX idx_messages_to ON messages(to_address)')\n",
    "\n",
    "# Drop unused email_documents table\n",
    "print(\"Dropping unused email_documents table...\")\n",
    "cursor.execute('DROP TABLE IF EXISTS email_documents')\n",
    "\n",
    "conn.commit()\n",
    "\n",
    "# Run VACUUM to compress and defragment\n",
    "print(\"Running VACUUM to compress database...\")\n",
    "cursor.execute('VACUUM')\n",
    "\n",
    "conn.close()\n",
    "\n",
    "# Get final database size\n",
    "final_size = os.path.getsize(DB_PATH) / 1024  # KB\n",
    "reduction = ((initial_size - final_size) / initial_size) * 100\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"Database Optimization Complete!\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"Initial size:  {initial_size:,.1f} KB\")\n",
    "print(f\"Final size:    {final_size:,.1f} KB\")\n",
    "print(f\"Reduction:     {reduction:.1f}% ({initial_size - final_size:,.1f} KB saved)\")\n",
    "print(f\"{'='*50}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the resulting file can now be copied to the \\data folder of the GUI"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
